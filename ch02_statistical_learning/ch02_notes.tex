
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{CH2\_Notes}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{statistical-learning}{%
\section{Statistical Learning}\label{statistical-learning}}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

    \hypertarget{what-is-statistical-learning}{%
\subsection{What is Statistical
Learning?}\label{what-is-statistical-learning}}

    Given paired data \((X, Y)\), assume a relationship between \(X\) and
\(Y\) modeled by

\[ Y = f(X) + \epsilon \]

where \(f:\mathbb{R}^p \rightarrow \mathbb{R}\) is a function and
\(\epsilon\) is a random error term with \(\mathbb{E}(\epsilon) = 0\).

\textbf{\emph{Statistical learning}} is a set of approaches for
estimating \(f\)0

    \hypertarget{why-estimate-f}{%
\subsubsection{\texorpdfstring{Why Estimate
\(f\)?}{Why Estimate f?}}\label{why-estimate-f}}

    \hypertarget{prediction}{%
\subparagraph{Prediction}\label{prediction}}

    \begin{itemize}
\item
  We may want to \textbf{\emph{predict}} the output \(Y\) from an
  estimate \(\hat{f}\) of \(f\). The predicted value for a given \(Y\)
  is then \[ \hat{Y} = \hat{f}(X)\]. In prediction, we often treat \(f\)
  as a \textbf{\emph{black-box}}
\item
  The mean squared-error2
  \(\mathbf{mse}(\hat{Y})=\mathbb{E}(Y-\hat{Y})^2\) is a good measure of
  the accuracy of \(\hat{Y}\) as a predictor for \(Y\).
\item
  One can write
\end{itemize}

\[ \mathbf{mse}(\hat{Y}) = \left(f(X) - \hat{f}(X)\right)^2 + \mathbb{V}(\epsilon) \]

These two terms are known as the \textbf{\emph{reducible error}} and
\textbf{\emph{irreducible error}}, respectively3

    \hypertarget{inference}{%
\subparagraph{Inference}\label{inference}}

    \begin{itemize}
\tightlist
\item
  Instead of predicting \(Y\) from \(X\), we may be more interested how
  \(Y\) changes as a function of \(X\). In inference, we usually do not
  treat \(f\) as a black box.
\end{itemize}

Examples of important inference questions:

\begin{itemize}
\tightlist
\item
  \emph{Which predictors have the largest influence on the response?}
\item
  \emph{What is the relationship between the response and each
  predictor?}
\item
  *Is f linear or non-linear?
\end{itemize}

    \hypertarget{how-to-estimate-f}{%
\subsubsection{\texorpdfstring{How to Estimate
\(f\)?}{How to Estimate f?}}\label{how-to-estimate-f}}

    \hypertarget{parametric-methods}{%
\subparagraph{Parametric methods}\label{parametric-methods}}

    Steps for parametric method:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Assume a parametric model for \(f\), that is assume a specific
  functional form4
\end{enumerate}

\[f = f(X, \boldsymbol{\beta}) \]

for some vector of \textbf{\emph{parameters}}
\(\boldsymbol{\beta} = (\beta_1,\dots,\beta_p)^T\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Use the training data to \textbf{\emph{fit}} or \textbf{\emph{train}}
  the model, that is to choose \(\beta_i\) such that
\end{enumerate}

\[Y \approx f(X, \boldsymbol{\beta})\]

    \hypertarget{non-parametric-methods}{%
\subparagraph{Non-parametric methods}\label{non-parametric-methods}}

    These methods make no assumptions about the functional form of \(f\).

    \hypertarget{accuracy-vs.-interpretability}{%
\subsubsection{Accuracy
vs.~Interpretability}\label{accuracy-vs.-interpretability}}

    \begin{itemize}
\item
  In inference, generally speaking the more flexible the method, the
  less interpretable.
\item
  In prediction, generally speaking the more flexible the method, the
  less accurate
\end{itemize}

    \hypertarget{supervised-vs.-unsupervised-learning}{%
\subsubsection{Supervised vs.~Unsupervised
Learning}\label{supervised-vs.-unsupervised-learning}}

    \begin{itemize}
\item
  In \textbf{\emph{supervised learning}}, training data consists of
  pairs \((X, Y)\) where \(X\) is a vector of predictors and \(Y\) a
  response. Prediction and inference are supervised learning problems,
  and the response variable (or the relationship between the response
  and the predictors) \emph{supervises} the analysis of model
\item
  In \textbf{\emph{unsupervised learning}}, training data lacks a
  response variable.
\end{itemize}

    \hypertarget{regression-vs.-classification}{%
\subsubsection{Regression
vs.~Classification}\label{regression-vs.-classification}}

    \begin{itemize}
\item
  Problems with a quantitative response
  (\(Y\in S \subseteq \mathbb{R}\)) tend to be called
  \textbf{\emph{regression}} problems
\item
  Problems with a qualitative, or categorical response
  (\(Y \in \{y_1, \dots, y_n\})\) tend to be called
  \textbf{\emph{classification}} problems
\end{itemize}

    \hypertarget{assessing-model-accuracy}{%
\subsection{Assessing Model Accuracy}\label{assessing-model-accuracy}}

    There is no free lunch in statistics

    \hypertarget{measuring-quality-of-fit}{%
\subsubsection{Measuring Quality of
Fit}\label{measuring-quality-of-fit}}

    \begin{itemize}
\item
  To evaluate the performance of a method on a data set, we need measure
  model accuracy (how well predictions match observed data).
\item
  In regression, the most common measure is the
  \textbf{\emph{mean-squared error}}
\end{itemize}

\[MSE = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{f}(x_i))^2\]

where \(y_i\) and \(\hat{f}(x_i)\) are the \(i\) true and predicting\\
responses, respectively.

\begin{itemize}
\item
  We are usually not interested in minimizing MSE with respect to
  training data but rather to test data.
\item
  There is no guarantee low training MSE will translate to low test MSE.
\item
  Having low training MSE but high test MSE is called
  \textbf{\emph{overfitting}}
\end{itemize}

    \hypertarget{the-bias-variance-tradeoff}{%
\subsubsection{The Bias-Variance
Tradeoff}\label{the-bias-variance-tradeoff}}

    \begin{itemize}
\tightlist
\item
  For a given \(x_0\), the expected 5 MSE can be written
\end{itemize}

\begin{align*}
\mathbb{E}\left[\left(y_0 - \hat{f}(x_0)\right)^2\right] 
&= \left(\mathbb{E}\left[\hat{f}(x) \right] - f(x)\right)^2 + \mathbb{E}\left[\left(\hat{f}(x_0) - \mathbb{E}\left[\hat{f}(x_0)\right]\right)^2\right] + \mathbb{E}\left[\left(\epsilon - \mathbb{E}[\epsilon]\right)^2\right]\\
&= \mathbf{bias}^2\left(\hat{f}(x_0))\right) + \mathbb{V}\left(\hat{f}(x_0)\right) + \mathbb{V}(\epsilon)
\end{align*}

\begin{itemize}
\item
  A good method minimizes variance and bias simultaneously.
\item
  As a general rule, these quantities are inversely proportional. More
  flexible methods have lower bias but higher variance, while less
  flexible methods have the opposite. This is the
  \textbf{\emph{bias-variance tradeoff}}
\item
  In practice the mse, variance and bias cannot be calculated exactly
  but one must keep the bias-variance tradeoff in mind.
\end{itemize}

    \hypertarget{the-classification-setting}{%
\subsubsection{The Classification
Setting}\label{the-classification-setting}}

    \begin{itemize}
\tightlist
\item
  In the classification setting, the most common measure of model
  accuracy is the \textbf{\emph{error rate}} 6
\end{itemize}

\[\frac{1}{n}\sum_{i=1}^n I(y_i \neq \hat{y}_i)\]

\begin{itemize}
\tightlist
\item
  As with the regression, we are interested in minimizing the test error
  rate, not the training error rate.
\end{itemize}

    \hypertarget{the-bayes-classifier}{%
\subparagraph{The Bayes Classifier}\label{the-bayes-classifier}}

    \begin{itemize}
\tightlist
\item
  Given \(K\) classes, the \textbf{\emph{Bayes Classifier}} predicts
\end{itemize}

\[ \hat{y_0} = \underset{1\leqslant j \leqslant K}{\text{argmax}\,} \mathbb{P}\left(Y=j\ |\ X = x_0\right)\]

\begin{itemize}
\item
  The set of points
  \[\{x_0\in\mathbb{R}^p\ |\ \mathbb{P}\left(Y=j\ |\ X = x_0\right) = \mathbb{P}\left(Y=k\ |\ X = x_0\right)\ \text{for all}\ 1\leqslant j,k \leqslant K\}\]

  is called the \textbf{\emph{Bayes decision boundary}}
\item
  The test error rate of the Bayes classifier is the \textbf{\emph{Bayes
  error rate}}, which is minimal among classifiers. It is given by
\end{itemize}

\[ 1 - \mathbb{E}\left(\underset{j}{\max} \mathbb{P}\left(Y=j\ |\ X\right)\right)\]

\begin{itemize}
\tightlist
\item
  The Bayes classifier is optimal, but in practice we don't know
  \(\mathbb{P}\left(Y\ |\ X\right)\).
\end{itemize}

    \hypertarget{k-nearest-neighbors}{%
\subparagraph{K-Nearest Neighbors}\label{k-nearest-neighbors}}

    \begin{itemize}
\tightlist
\item
  The \textbf{\emph{K-nearest neighbors}} classifier works by estimating
  \(\mathbb{P}\left(Y\ |\ X\right)\) as follows.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Given \(K\geqslant 1\) and \(x_0\), find the set of points
\end{enumerate}

\[ \mathcal{N}_0 = \{K\ \text{nearest points to}\ x_0\}\subseteq\mathbb{R}^p \]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  For each class \(j\) set
\end{enumerate}

\[ \mathbb{P}\left(Y=j\ |\ X\right) = \frac{1}{K}\sum_{x_i\in\mathcal{N}_0}I(y_i = j)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Predict
\end{enumerate}

\[ \hat{y_0} = \underset{1\leqslant j \leqslant K}{\text{argmax}\,} \mathbb{P}\left(Y=j\ |\ X = x_0\right)\]
\_\_\_

    \hypertarget{footnotes}{%
\subsection{Footnotes}\label{footnotes}}

    \hypertarget{foot0}{}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\tightlist
\item
  Reading the rest of the chapter, one realized this is the situation
  for \emph{supervised} learning, which is the vast majority of this
  book is concerned with. ↩
\end{enumerate}

\hypertarget{foot1}{}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Here \(X=(X_1,\dots, X_p)^T\) is a vector. ↩
\end{enumerate}

\hypertarget{foot2}{}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  This is usual definition of the mean squared-error of \(\hat{Y}\) as
  an estimator of the (non-parametric) quantity \(Y=f(X)\). ↩
\end{enumerate}

\hypertarget{foot3}{}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  We can in principle control the reducible error by improving the
  estimate \(\hat{f}\), but we cannot control the irreducible error. ↩
\end{enumerate}

\hypertarget{foot4}{}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  For example, a simple but popular assumption is that f is linear in
  both the parameters and the features, that is:
\end{enumerate}

\[f(X) = \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p\]

This is linear regression. ↩

\hypertarget{foot5}{}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Here the random variable is \(\hat{f}(x_0)\), so the average is taken
  over all data sets ↩
\end{enumerate}

\hypertarget{foot6}{}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  This is just the proportion of misclassified observations. ↩
\end{enumerate}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
