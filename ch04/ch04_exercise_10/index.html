<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      4. Logistic Regression &middot; islr
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/islr/public/css/poole.css">
  <link rel="stylesheet" href="/islr/public/css/syntax.css">
  <link rel="stylesheet" href="/islr/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/islr/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/islr/public/favicon.ico">
  --->

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!--- KaTeX --->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
      onload="renderMathInElement(document.body);"></script>
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/islr/">Home</a>

    
    
      
    
      
        
      
    
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch02/">2. Statistical Learning</a>
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch03/">3. Linear Regression</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch04/">4. Logistic Regression</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch05/">5. Resampling Methods</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch06/">6. Linear Model Selection and Regularization</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch07/">7. Moving Beyond Linearity</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch08/">8. Tree-Based Methods</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch09/">9. Support Vector Machines</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch10/">10. Unsupervised Learning</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
    
      
    
      
    
      
    

  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2019.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/islr/" title="Home">islr</a>
            <small>notes and exercises from An Introduction to Statistical Learning</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="page">
  <h1 class="page-title">4. Logistic Regression</h1>
  	
<h1 id="exercise-10-classifying-direction-in-the-weekly-dataset">Exercise 10: Classifying <code class="highlighter-rouge">Direction</code> in the <code class="highlighter-rouge">Weekly</code> dataset</h1>

<div class="toc">
  <ul class="toc-item"><li><span><a href="#reparing-the-data" data-toc-modified-id="Preparing-the-Data-1">Preparing the Data</a></span><ul class="toc-item"><li><span><a href="#import" data-toc-modified-id="Import-1.1">Import</a></span></li><li><span><a href="#preprocessing" data-toc-modified-id="Preprocessing-1.2">Preprocessing</a></span><ul class="toc-item"><li><span><a href="#Converting-qualitative-variables-to-quantitative" data-toc-modified-id="Converting-qualitative-variables-to-quantitative-1.2.1">Converting qualitative variables to quantitative</a></span></li></ul></li></ul></li><li><span><a href="#a-numerical-and-graphical-summaries" data-toc-modified-id="a.-Numerical-and-graphical-summaries-2">a. Numerical and graphical summaries</a></span><ul class="toc-item"><li><span><a href="#the-return-variables-are-concentrated" data-toc-modified-id="The-return-variables-are-concentrated-2.1">The return variables are concentrated</a></span></li><li><span><a href="#return-variables-are-nearly-uncorrelated" data-toc-modified-id="Return-variables-are-nearly-uncorrelated-2.2">Return variables are nearly uncorrelated</a></span></li><li><span><a href="#volume-correlates-with-year" data-toc-modified-id="Volume-correlates-with-Year-2.3"><code>Volume</code> correlates with <code>Year</code></a></span></li></ul></li><li><span><a href="#b-logistic-regression-classification-of-direction-using-lag-and-volume-predictors" data-toc-modified-id="b.-Logistic-Regression-Classification-of-Direction-using-Lag-and-Volume-predictors-3">b. Logistic Regression Classification of <code>Direction</code> using <code>Lag</code> and <code>Volume</code> predictors</a></span></li><li><span><a href="#c-confusion-matrix" data-toc-modified-id="c.-Confusion-Matrix-4">c. Confusion Matrix</a></span><ul class="toc-item"><li><span><a href="#performance-rates-of-interest-from-the-confusion-matrix" data-toc-modified-id="Performance-rates-of-interest-from-the-confusion-matrix-4.1">Performance rates of interest from the confusion matrix</a></span></li><li><span><a href="#analyzing-model-performance-rates" data-toc-modified-id="Analyzing-model-performance-rates-4.2">Analyzing model performance rates</a></span><ul class="toc-item"><li><span><a href="#observations" data-toc-modified-id="Observations-4.2.1">Observations</a></span></li></ul></li></ul></li><li><span><a href="#d-logistic-regression-classification-of-direction-using-lag2-predictor" data-toc-modified-id="d.-Logistic-Regression-Classification-of-Direction-using-Lag2-predictor-5">d. Logistic Regression Classification of <code>Direction</code> using <code>Lag2</code> predictor</a></span></li><li><span><a href="#e--other-classification-models-of-direction-using-lag2-predictor" data-toc-modified-id="e.--Other-classification-models-of-Direction-using-Lag2-predictor-6">e.  Other classification models of <code>Direction</code> using <code>Lag2</code> predictor</a></span><ul class="toc-item"><li><span><a href="#lda" data-toc-modified-id="LDA-6.1">LDA</a></span></li><li><span><a href="#qda" data-toc-modified-id="QDA-6.2">QDA</a></span></li><li><span><a href="#knn" data-toc-modified-id="KNN-6.3">KNN</a></span></li><li><span><a href="comparing-results" data-toc-modified-id="Comparing-results-6.4">Comparing results</a></span></li></ul></li><li><span><a href="#h-which-method-has-the-best-results?" data-toc-modified-id="h.-Which-method-has-the-best-results?-7">h. Which method has the best results?</a></span></li><li><span><a href="#i-feature-and-model-selection" data-toc-modified-id="i.-Feature-and-Model-Selection-8">i. Feature and Model Selection</a></span><ul class="toc-item"><li><span><a href="#get-all-predictor-interactions" data-toc-modified-id="Get-all-predictor-interactions-8.1">Get all predictor interactions</a></span></li><li><span><a href="#choose-some-transformations" data-toc-modified-id="Choose-some-transformations-8.2">Choose some transformations</a></span></li><li><span><a href="#Rrndom-data-tweak" data-toc-modified-id="Random-data-tweak-8.3">Random data tweak</a></span></li><li><span><a href="#comparison-of-logit-lda-qda-and-knn-models-on-a-single-random-data-tweak" data-toc-modified-id="Comparison-of-Logit,-LDA,-QDA,-and-KNN-models-on-a-single-random-data-tweak-8.4">Comparison of Logit, LDA, QDA, and KNN models on a single random data tweak</a></span></li><li><span>&lt;a href="#comparison-of-logit-lda-qda-and-knn-models-over-<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span>-data-tweaks" data-toc-modified-id="Comparison-of-Logit,-LDA,-QDA,-and-KNN-models-over-<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span>-data-tweaks-8.5"&gt;Comparison of Logit, LDA, QDA, and KNN models over <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span> data tweaks&lt;/a&gt;</span></li><li><span><a href="#analysis-of-comparisons" data-toc-modified-id="Analysis-of-Comparisons-8.6">Analysis of Comparisons</a></span><ul class="toc-item"><li><span><a href="#analyzing-accuracy-across-models" data-toc-modified-id="Analyzing-accuracy-across-models-8.6.1">Analyzing accuracy across models</a></span><ul class="toc-item"><li><span><a href="#summary-statistics" data-toc-modified-id="Summary-statistics-8.6.1.1">Summary statistics</a></span></li><li><span><a href="#distributions-of-accuracy-across-models" data-toc-modified-id="Distributions-of-accuracy-across-models-8.6.1.2">Distributions of accuracy across models</a></span></li></ul></li></ul></li></ul></li></ul>
</div>

<h2 id="preparing-the-data">Preparing the Data</h2>

<h3 id="import">Import</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">weekly</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'../../datasets/Weekly.csv'</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">weekly</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>Year</th>
      <th>Lag1</th>
      <th>Lag2</th>
      <th>Lag3</th>
      <th>Lag4</th>
      <th>Lag5</th>
      <th>Volume</th>
      <th>Today</th>
      <th>Direction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1990</td>
      <td>0.816</td>
      <td>1.572</td>
      <td>-3.936</td>
      <td>-0.229</td>
      <td>-3.484</td>
      <td>0.154976</td>
      <td>-0.270</td>
      <td>Down</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1990</td>
      <td>-0.270</td>
      <td>0.816</td>
      <td>1.572</td>
      <td>-3.936</td>
      <td>-0.229</td>
      <td>0.148574</td>
      <td>-2.576</td>
      <td>Down</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1990</td>
      <td>-2.576</td>
      <td>-0.270</td>
      <td>0.816</td>
      <td>1.572</td>
      <td>-3.936</td>
      <td>0.159837</td>
      <td>3.514</td>
      <td>Up</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1990</td>
      <td>3.514</td>
      <td>-2.576</td>
      <td>-0.270</td>
      <td>0.816</td>
      <td>1.572</td>
      <td>0.161630</td>
      <td>0.712</td>
      <td>Up</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1990</td>
      <td>0.712</td>
      <td>3.514</td>
      <td>-2.576</td>
      <td>-0.270</td>
      <td>0.816</td>
      <td>0.153728</td>
      <td>1.178</td>
      <td>Up</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weekly</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 1089 entries, 1 to 1089
Data columns (total 9 columns):
Year         1089 non-null int64
Lag1         1089 non-null float64
Lag2         1089 non-null float64
Lag3         1089 non-null float64
Lag4         1089 non-null float64
Lag5         1089 non-null float64
Volume       1089 non-null float64
Today        1089 non-null float64
Direction    1089 non-null object
dtypes: float64(7), int64(1), object(1)
memory usage: 85.1+ KB
</code></pre></div></div>

<h3 id="preprocessing">Preprocessing</h3>

<h4 id="converting-qualitative-variables-to-quantitative">Converting qualitative variables to quantitative</h4>

<p>Don’t see any null values but let’s check</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weekly</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0
</code></pre></div></div>

<p><code class="highlighter-rouge">Direction</code> is a qualitative variable encoded as a string; let’s encode it numerically</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sklearn.preprocessing</span> <span class="k">as</span> <span class="n">skl_preprocessing</span>

<span class="c"># create and fit label encoder</span>
<span class="n">direction_le</span> <span class="o">=</span> <span class="n">skl_preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">direction_le</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">weekly</span><span class="o">.</span><span class="n">Direction</span><span class="p">)</span>

<span class="c"># replace string encoding with numeric</span>
<span class="n">weekly</span><span class="p">[</span><span class="s">'Direction_num'</span><span class="p">]</span> <span class="o">=</span> <span class="n">direction_le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">weekly</span><span class="o">.</span><span class="n">Direction</span><span class="p">)</span>
<span class="n">weekly</span><span class="o">.</span><span class="n">Direction_num</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1    0
2    0
3    1
4    1
5    1
Name: Direction_num, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">direction_le</span><span class="o">.</span><span class="n">classes_</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array(['Down', 'Up'], dtype=object)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">direction_le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">direction_le</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0, 1])
</code></pre></div></div>

<p>So the encoding is {<code class="highlighter-rouge">Down</code>:0, <code class="highlighter-rouge">Up</code>:1}</p>

<h2 id="a-numerical-and-graphical-summaries">a. Numerical and graphical summaries</h2>

<p>Here’s a description of the dataset from the <code class="highlighter-rouge">R</code> documentation</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Weekly S&amp;P Stock Market Data

Description

Weekly percentage returns for the S&amp;P 500 stock index between 1990 and 2010.

Usage

Weekly
Format

A data frame with 1089 observations on the following 9 variables.

Year
The year that the observation was recorded

Lag1
Percentage return for previous week

Lag2
Percentage return for 2 weeks previous

Lag3
Percentage return for 3 weeks previous

Lag4
Percentage return for 4 weeks previous

Lag5
Percentage return for 5 weeks previous

Volume
Volume of shares traded (average number of daily shares traded in billions)

Today
Percentage return for this week

Direction
A factor with levels Down and Up indicating whether the market had a positive or negative return on a given week

Source

Raw values of the S&amp;P 500 were obtained from Yahoo Finance and then converted to percentages and lagged.
</code></pre></div></div>

<p>Let’s look at summary statistics</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weekly</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>Year</th>
      <th>Lag1</th>
      <th>Lag2</th>
      <th>Lag3</th>
      <th>Lag4</th>
      <th>Lag5</th>
      <th>Volume</th>
      <th>Today</th>
      <th>Direction_num</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1089.000000</td>
      <td>1089.000000</td>
      <td>1089.000000</td>
      <td>1089.000000</td>
      <td>1089.000000</td>
      <td>1089.000000</td>
      <td>1089.000000</td>
      <td>1089.000000</td>
      <td>1089.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2000.048669</td>
      <td>0.150585</td>
      <td>0.151079</td>
      <td>0.147205</td>
      <td>0.145818</td>
      <td>0.139893</td>
      <td>1.574618</td>
      <td>0.149899</td>
      <td>0.555556</td>
    </tr>
    <tr>
      <th>std</th>
      <td>6.033182</td>
      <td>2.357013</td>
      <td>2.357254</td>
      <td>2.360502</td>
      <td>2.360279</td>
      <td>2.361285</td>
      <td>1.686636</td>
      <td>2.356927</td>
      <td>0.497132</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1990.000000</td>
      <td>-18.195000</td>
      <td>-18.195000</td>
      <td>-18.195000</td>
      <td>-18.195000</td>
      <td>-18.195000</td>
      <td>0.087465</td>
      <td>-18.195000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1995.000000</td>
      <td>-1.154000</td>
      <td>-1.154000</td>
      <td>-1.158000</td>
      <td>-1.158000</td>
      <td>-1.166000</td>
      <td>0.332022</td>
      <td>-1.154000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2000.000000</td>
      <td>0.241000</td>
      <td>0.241000</td>
      <td>0.241000</td>
      <td>0.238000</td>
      <td>0.234000</td>
      <td>1.002680</td>
      <td>0.241000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2005.000000</td>
      <td>1.405000</td>
      <td>1.409000</td>
      <td>1.409000</td>
      <td>1.409000</td>
      <td>1.405000</td>
      <td>2.053727</td>
      <td>1.405000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2010.000000</td>
      <td>12.026000</td>
      <td>12.026000</td>
      <td>12.026000</td>
      <td>12.026000</td>
      <td>12.026000</td>
      <td>9.328214</td>
      <td>12.026000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<ul>
  <li>
    <p>All the variables ranges look good (e.g. no negative values for volume)</p>
  </li>
  <li>
    <p>The <code class="highlighter-rouge">Lag</code> variables and <code class="highlighter-rouge">Today</code> all have very similar summary statistics, as expected.</p>
  </li>
  <li>
    <p>Of particular interest is <code class="highlighter-rouge">Direction_num</code>, which has a mean of <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≈</mo><mn>0.56</mn></mrow><annotation encoding="application/x-tex">\approx 0.56</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.48312em;vertical-align:0em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mord">6</span></span></span></span> and a standard deviation of <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≈</mo><mn>0.50</mn></mrow><annotation encoding="application/x-tex">\approx 0.50</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.48312em;vertical-align:0em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mord">0</span></span></span></span>! 
That’s what we’ll be trying to predict later in the exercise, which will be interesting.</p>
  </li>
</ul>

<p>Let’s look at distributions</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s">'seaborn-white'</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">'white'</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">warnings</span>  
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">weekly</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'Direction'</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.PairGrid at 0x1a2515d208&gt;
</code></pre></div></div>

<p><img src="/islr/assets/images/ch04_exercise_10_22_1.png" alt="png" /></p>

<h3 id="the-return-variables-are-concentrated">The return variables are concentrated</h3>

<p>The return variables  (i.e. <code class="highlighter-rouge">Lag</code> and <code class="highlighter-rouge">Today</code> variables) are “tight” instead of spread out, i.e. fairly concentrated about their mean.</p>

<p>Here are the deviations of all variables as percentages of the magnitude of their ranges</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weekly_num</span> <span class="o">=</span> <span class="n">weekly</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Direction'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">round</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="p">(</span><span class="n">weekly_num</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">weekly_num</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">weekly_num</span><span class="o">.</span><span class="nb">min</span><span class="p">())),</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Year             30.17
Lag1              7.80
Lag2              7.80
Lag3              7.81
Lag4              7.81
Lag5              7.81
Volume           18.25
Today             7.80
Direction_num    49.71
dtype: float64
</code></pre></div></div>

<h3 id="return-variables-are-nearly-uncorrelated">Return variables are nearly uncorrelated</h3>

<p>In the pairplot there is a visible lack of pairwise sample correlation among the return variables.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weekly</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>Year</th>
      <th>Lag1</th>
      <th>Lag2</th>
      <th>Lag3</th>
      <th>Lag4</th>
      <th>Lag5</th>
      <th>Volume</th>
      <th>Today</th>
      <th>Direction_num</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Year</th>
      <td>1.000000</td>
      <td>-0.032289</td>
      <td>-0.033390</td>
      <td>-0.030006</td>
      <td>-0.031128</td>
      <td>-0.030519</td>
      <td>0.841942</td>
      <td>-0.032460</td>
      <td>-0.022200</td>
    </tr>
    <tr>
      <th>Lag1</th>
      <td>-0.032289</td>
      <td>1.000000</td>
      <td>-0.074853</td>
      <td>0.058636</td>
      <td>-0.071274</td>
      <td>-0.008183</td>
      <td>-0.064951</td>
      <td>-0.075032</td>
      <td>-0.050004</td>
    </tr>
    <tr>
      <th>Lag2</th>
      <td>-0.033390</td>
      <td>-0.074853</td>
      <td>1.000000</td>
      <td>-0.075721</td>
      <td>0.058382</td>
      <td>-0.072499</td>
      <td>-0.085513</td>
      <td>0.059167</td>
      <td>0.072696</td>
    </tr>
    <tr>
      <th>Lag3</th>
      <td>-0.030006</td>
      <td>0.058636</td>
      <td>-0.075721</td>
      <td>1.000000</td>
      <td>-0.075396</td>
      <td>0.060657</td>
      <td>-0.069288</td>
      <td>-0.071244</td>
      <td>-0.022913</td>
    </tr>
    <tr>
      <th>Lag4</th>
      <td>-0.031128</td>
      <td>-0.071274</td>
      <td>0.058382</td>
      <td>-0.075396</td>
      <td>1.000000</td>
      <td>-0.075675</td>
      <td>-0.061075</td>
      <td>-0.007826</td>
      <td>-0.020549</td>
    </tr>
    <tr>
      <th>Lag5</th>
      <td>-0.030519</td>
      <td>-0.008183</td>
      <td>-0.072499</td>
      <td>0.060657</td>
      <td>-0.075675</td>
      <td>1.000000</td>
      <td>-0.058517</td>
      <td>0.011013</td>
      <td>-0.018168</td>
    </tr>
    <tr>
      <th>Volume</th>
      <td>0.841942</td>
      <td>-0.064951</td>
      <td>-0.085513</td>
      <td>-0.069288</td>
      <td>-0.061075</td>
      <td>-0.058517</td>
      <td>1.000000</td>
      <td>-0.033078</td>
      <td>-0.017995</td>
    </tr>
    <tr>
      <th>Today</th>
      <td>-0.032460</td>
      <td>-0.075032</td>
      <td>0.059167</td>
      <td>-0.071244</td>
      <td>-0.007826</td>
      <td>0.011013</td>
      <td>-0.033078</td>
      <td>1.000000</td>
      <td>0.720025</td>
    </tr>
    <tr>
      <th>Direction_num</th>
      <td>-0.022200</td>
      <td>-0.050004</td>
      <td>0.072696</td>
      <td>-0.022913</td>
      <td>-0.020549</td>
      <td>-0.018168</td>
      <td>-0.017995</td>
      <td>0.720025</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>Indeed the magnitudes of the sample correlations for these pairs are quite small.</p>

<h3 id="volume-correlates-with-year"><code class="highlighter-rouge">Volume</code> correlates with <code class="highlighter-rouge">Year</code></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">weekly</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s">'Year'</span><span class="p">,</span> <span class="s">'Volume'</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="s">'Direction'</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.PairGrid at 0x1a28503780&gt;
</code></pre></div></div>

<p><img src="/islr/assets/images/ch04_exercise_10_31_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">weekly</span><span class="o">.</span><span class="n">Year</span><span class="p">,</span> <span class="n">weekly</span><span class="o">.</span><span class="n">Volume</span><span class="p">,</span> <span class="n">lowess</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a2a543be0&gt;
</code></pre></div></div>

<p><img src="/islr/assets/images/ch04_exercise_10_32_1.png" alt="png" /></p>

<h2 id="b-logistic-regression-classification-of-direction-using-lag-and-volume-predictors">b. Logistic Regression Classification of <code class="highlighter-rouge">Direction</code> using <code class="highlighter-rouge">Lag</code> and <code class="highlighter-rouge">Volume</code> predictors</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>

<span class="c"># predictor labels</span>
<span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Lag'</span> <span class="o">+</span> <span class="n">stri</span><span class="o">.</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span>
<span class="n">predictors</span> <span class="o">+=</span> <span class="p">[</span><span class="s">'Volume'</span><span class="p">]</span>

<span class="c"># fit and summarize model</span>

<span class="n">sm_logit_model_full</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Logit</span><span class="p">(</span><span class="n">weekly</span><span class="o">.</span><span class="n">Direction_num</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">weekly</span><span class="p">[</span><span class="n">predictors</span><span class="p">]))</span>
<span class="n">sm_logit_model_full</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Optimization terminated successfully.
         Current function value: 0.682441
         Iterations 4
</code></pre></div></div>

<table class="simpletable">
<caption>Logit Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>   <td>Direction_num</td>  <th>  No. Observations:  </th>  <td>  1089</td> 
</tr>
<tr>
  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1082</td> 
</tr>
<tr>
  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td> 
</tr>
<tr>
  <th>Date:</th>          <td>Mon, 26 Nov 2018</td> <th>  Pseudo R-squ.:     </th> <td>0.006580</td>
</tr>
<tr>
  <th>Time:</th>              <td>17:27:33</td>     <th>  Log-Likelihood:    </th> <td> -743.18</td>
</tr>
<tr>
  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -748.10</td>
</tr>
<tr>
  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.1313</td> 
</tr>
</table>
<table class="simpletable">
<tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>  <td>    0.2669</td> <td>    0.086</td> <td>    3.106</td> <td> 0.002</td> <td>    0.098</td> <td>    0.435</td>
</tr>
<tr>
  <th>Lag1</th>   <td>   -0.0413</td> <td>    0.026</td> <td>   -1.563</td> <td> 0.118</td> <td>   -0.093</td> <td>    0.010</td>
</tr>
<tr>
  <th>Lag2</th>   <td>    0.0584</td> <td>    0.027</td> <td>    2.175</td> <td> 0.030</td> <td>    0.006</td> <td>    0.111</td>
</tr>
<tr>
  <th>Lag3</th>   <td>   -0.0161</td> <td>    0.027</td> <td>   -0.602</td> <td> 0.547</td> <td>   -0.068</td> <td>    0.036</td>
</tr>
<tr>
  <th>Lag4</th>   <td>   -0.0278</td> <td>    0.026</td> <td>   -1.050</td> <td> 0.294</td> <td>   -0.080</td> <td>    0.024</td>
</tr>
<tr>
  <th>Lag5</th>   <td>   -0.0145</td> <td>    0.026</td> <td>   -0.549</td> <td> 0.583</td> <td>   -0.066</td> <td>    0.037</td>
</tr>
<tr>
  <th>Volume</th> <td>   -0.0227</td> <td>    0.037</td> <td>   -0.616</td> <td> 0.538</td> <td>   -0.095</td> <td>    0.050</td>
</tr>
</table>

<p>Only the intercept and <code class="highlighter-rouge">Lag2</code> and appear to be statistically significant</p>

<h2 id="c-confusion-matrix">c. Confusion Matrix</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="k">as</span> <span class="n">skl_linear_model</span>

<span class="c"># fit model</span>
<span class="n">skl_logit_model_full</span> <span class="o">=</span> <span class="n">skl_linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">weekly</span><span class="p">[</span><span class="n">predictors</span><span class="p">])</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">weekly</span><span class="o">.</span><span class="n">Direction_num</span><span class="o">.</span><span class="n">values</span>
<span class="n">skl_logit_model_full</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># check paramaters are close in the two models</span>
<span class="nb">abs</span><span class="p">(</span><span class="n">skl_logit_model_full</span><span class="o">.</span><span class="n">coef_</span> <span class="o">-</span> <span class="n">sm_logit_model_full</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Optimization terminated successfully.
         Current function value: 0.682441
         Iterations 4





array([[1.33953314e-01, 6.15092984e-05, 3.94405141e-06, 4.06643634e-05,
        5.96004698e-05, 3.92562567e-05, 3.22507048e-04]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="n">skl_metrics</span>

<span class="c"># confusion matrix</span>
<span class="n">confusion_array</span> <span class="o">=</span> <span class="n">skl_metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">skl_logit_model_full</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">confusion_array</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[ 54, 430],
       [ 47, 558]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># confusion data frame</span>
<span class="n">col_index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="o">.</span><span class="n">from_product</span><span class="p">([[</span><span class="s">'Pred'</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">row_index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="o">.</span><span class="n">from_product</span><span class="p">([[</span><span class="s">'Actual'</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">confusion_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">confusion_array</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">col_index</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">row_index</span><span class="p">)</span>
<span class="n">confusion_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:</span> <span class="p">,(</span><span class="s">'Pred'</span><span class="p">,</span><span class="s">'Total'</span><span class="p">)]</span> <span class="o">=</span> <span class="n">confusion_df</span><span class="o">.</span><span class="n">Pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">confusion_df</span><span class="o">.</span><span class="n">Pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">confusion_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="s">'Actual'</span><span class="p">,</span><span class="s">'Total'</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">confusion_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="s">'Actual'</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">:]</span> <span class="o">+</span> 
                                        <span class="n">confusion_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="s">'Actual'</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">:])</span>
<span class="n">confusion_df</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'int32'</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead tr th {
        text-aligned: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th colspan="3" haligned="left">Pred</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>Total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valigned="top">Actual</th>
      <th>0</th>
      <td>54</td>
      <td>430</td>
      <td>484</td>
    </tr>
    <tr>
      <th>1</th>
      <td>47</td>
      <td>558</td>
      <td>605</td>
    </tr>
    <tr>
      <th>Total</th>
      <td>101</td>
      <td>988</td>
      <td>1089</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="performance-rates-of-interest-from-the-confusion-matrix">Performance rates of interest from the confusion matrix</h3>

<p>Recall that for a binary classifier the confusion matrix shows</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>Pred</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>Actual</mtext><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>T</mi><mi>N</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>F</mi><mi>P</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>N</mi><mi>e</mi><mi>g</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>F</mi><mi>N</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>T</mi><mi>P</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>P</mi><mi>o</mi><mi>s</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>N</mi><mi>e</mi><mi>g</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>P</mi><mi>o</mi><mi>s</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>n</mi></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{matrix}
\text{Pred} \\
\text{Actual}
\begin{pmatrix}
TN &amp; FP &amp; ActNeg\\
FN &amp; TP &amp; ActPos\\
PredNeg &amp; PredPos &amp; n
\end{pmatrix}
\end{matrix}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.80004em;vertical-align:-2.15002em;"></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.65002em;"><span style="top:-5.860040000000001em;"><span class="pstrut" style="height:4.05002em;"></span><span class="mord"><span class="mord text"><span class="mord">Pred</span></span></span></span><span style="top:-3.45002em;"><span class="pstrut" style="height:4.05002em;"></span><span class="mord"><span class="mord text"><span class="mord">Actual</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎝</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎛</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05002em;"><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎠</span></span></span><span style="top:-4.05002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55002em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.15002em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>

<p>where</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>T</mi><mi>P</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>True Positives</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>F</mi><mi>P</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>False Positives</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>F</mi><mi>N</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>False Negatives</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>T</mi><mi>N</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>True Negatives</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>N</mi><mi>e</mi><mi>g</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>Total Actual Negatives</mtext><mo>=</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>P</mi><mi>o</mi><mi>s</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>Total Actual Positives</mtext><mo>=</mo><mi>F</mi><mi>N</mi><mo>+</mo><mi>T</mi><mi>P</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>N</mi><mi>e</mi><mi>g</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>Total Predicted Negatives</mtext><mo>=</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>P</mi><mi>o</mi><mi>s</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>Total Predicted Positives</mtext><mo>=</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>P</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
TP &amp; = \text{True Positives}\\
FP &amp; = \text{False Positives}\\
FN &amp; = \text{False Negatives}\\
TN &amp; = \text{True Negatives}\\
ActNeg &amp;= \text{Total Actual Negatives} = TN + FP\\
ActPos &amp;= \text{Total Actual Positives} = FN + TP\\
PredNeg &amp;= \text{Total Predicted Negatives} = TN + FN\\
PredPos &amp;= \text{Total Predicted Positives} = FP + TP\\
\end{aligned}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:12.000000000000002em;vertical-align:-5.750000000000001em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:6.250000000000001em;"><span style="top:-8.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span><span style="top:-6.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.9099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span><span style="top:-2.4099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span><span style="top:-0.9099999999999988em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span></span></span><span style="top:0.5900000000000007em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span><span style="top:2.0900000000000007em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.750000000000001em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:6.250000000000001em;"><span style="top:-8.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord">True Positives</span></span></span></span><span style="top:-6.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord">False Positives</span></span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord">False Negatives</span></span></span></span><span style="top:-3.9099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord">True Negatives</span></span></span></span><span style="top:-2.4099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord">Total Actual Negatives</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span><span style="top:-0.9099999999999988em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord">Total Actual Positives</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span><span style="top:0.5900000000000007em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord">Total Predicted Negatives</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span><span style="top:2.0900000000000007em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord">Total Predicted Positives</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.750000000000001em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>

<p>Also recall the following rates of interest</p>

<ul>
  <li>The <strong><em>accuracy</em></strong> of the classifier is the proportion of correctly classified observations</li>
</ul>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow><mi>n</mi></mfrac></mrow><annotation encoding="application/x-tex"> \frac{TP + TN}{n} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.04633em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>

<p>i.e., “How often is the model right?”</p>

<ul>
  <li>The <strong><em>misclassification rate</em></strong> (or <strong><em>error rate</em></strong>) is the proportion of incorrectly classified observations</li>
</ul>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow><mi>n</mi></mfrac></mrow><annotation encoding="application/x-tex"> \frac{FP + FN}{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.04633em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>

<p>i.e., “How often is the model wrong?”</p>

<ul>
  <li>The <strong><em>null error rate</em></strong> is the proportion of the majority class</li>
</ul>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>max</mi><mo>⁡</mo><mo stretchy="false">{</mo><mi>A</mi><mi>c</mi><mi>t</mi><mi>N</mi><mi>e</mi><mi>g</mi><mo separator="true">,</mo><mi>A</mi><mi>c</mi><mi>t</mi><mi>P</mi><mi>o</mi><mi>s</mi><mo stretchy="false">}</mo></mrow><mi>n</mi></mfrac></mrow><annotation encoding="application/x-tex"> \frac{\max\{ActNeg, ActPos\}}{n} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.113em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">max</span><span class="mopen">{</span><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mclose">}</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>

<p>i.e. “How often would we be wrong if we always predicted the majority class”</p>

<ul>
  <li>The <strong><em>true positive rate</em></strong> (or <strong><em>sensitivity</em></strong> or <strong><em>recall</em></strong>) is the ratio of true positives to actual positives</li>
</ul>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>P</mi><mi>o</mi><mi>s</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex"> \frac{TP}{ActPos} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.04633em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>

<p>, “How often is the model right for actual positives (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">Y=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>)?”</p>

<ul>
  <li>The <strong><em>false positive rate</em></strong> is the ratio of false positives to actual negatives</li>
</ul>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>N</mi><mi>e</mi><mi>g</mi></mrow></mfrac><mo>=</mo></mrow><annotation encoding="application/x-tex"> \frac{FP}{ActNeg}  = </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.2407700000000004em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span></span></span></span></p>

<p>i.e., “How often is the model wrong for actual positives?”</p>

<ul>
  <li>The <strong><em>true negative rate</em></strong> or <strong><em>specificity</em></strong> is the ratio of true negatives to actual negatives</li>
</ul>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>T</mi><mi>N</mi></mrow><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>N</mi><mi>e</mi><mi>g</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex"> \frac{TN}{ActNeg} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.2407700000000004em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>

<p>i.e., “How often is the model right for actual negatives (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">Y=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>)?”</p>

<ul>
  <li>The <strong><em>false negative rate</em></strong> is the ratio of true negatives to actual negatives</li>
</ul>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>F</mi><mi>N</mi></mrow><mrow><mi>A</mi><mi>c</mi><mi>t</mi><mi>N</mi><mi>e</mi><mi>g</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex"> \frac{FN}{ActNeg} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.2407700000000004em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>

<p>i.e., “How often is the model wrong for actual negatives (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">Y=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>)?”</p>

<ul>
  <li>The <strong><em>precision</em></strong> is the ratio of true positives to predicted positives</li>
</ul>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>P</mi><mi>o</mi><mi>s</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex"> \frac{TP}{PredPos} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.04633em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>

<p>i.e., “How often are the models’ positive predictions right?”</p>

<ul>
  <li>The <strong><em>prevalence</em></strong> is the ratio of actual positives to total observations</li>
</ul>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>F</mi><mi>N</mi><mo>+</mo><mi>T</mi><mi>P</mi></mrow><mi>n</mi></mfrac></mrow><annotation encoding="application/x-tex"> \frac{FN + TP}{n} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.04633em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>

<p>i.e., “How often do actual positives occur in the sample?”</p>

<h3 id="analyzing-model-performance-rates">Analyzing model performance rates</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># necessary variables</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">confusion_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="s">'Actual'</span><span class="p">,</span> <span class="s">'Total'</span><span class="p">),</span> <span class="p">(</span><span class="s">'Pred'</span><span class="p">,</span> <span class="s">'Total'</span><span class="p">)]</span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">confusion_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="s">'Actual'</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="s">'Pred'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">confusion_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="s">'Actual'</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="s">'Pred'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="n">FN</span> <span class="o">=</span> <span class="n">confusion_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="s">'Actual'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s">'Pred'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="s">'Actual'</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s">'Pred'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

<span class="c"># compute rates</span>
<span class="n">rates</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">rates</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
<span class="n">rates</span><span class="p">[</span><span class="s">'error rate'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
<span class="n">rates</span><span class="p">[</span><span class="s">'null error'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">,</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
<span class="n">rates</span><span class="p">[</span><span class="s">'TP rate'</span><span class="p">]</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
<span class="n">rates</span><span class="p">[</span><span class="s">'FP rate'</span><span class="p">]</span> <span class="o">=</span> <span class="n">FP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
<span class="n">rates</span><span class="p">[</span><span class="s">'TN rate'</span><span class="p">]</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span>
<span class="n">rates</span><span class="p">[</span><span class="s">'FN rate'</span><span class="p">]</span> <span class="o">=</span> <span class="n">FN</span> <span class="o">/</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span>
<span class="n">rates</span><span class="p">[</span><span class="s">'precision'</span><span class="p">]</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
<span class="n">rates</span><span class="p">[</span><span class="s">'prevalence'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>


<span class="c"># store results</span>
<span class="n">model_perf_rates_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rates</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">model_perf_rates_df</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>accuracy</th>
      <th>error rate</th>
      <th>null error</th>
      <th>TP rate</th>
      <th>FP rate</th>
      <th>TN rate</th>
      <th>FN rate</th>
      <th>precision</th>
      <th>prevalence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.561983</td>
      <td>0.438017</td>
      <td>0.555556</td>
      <td>0.922314</td>
      <td>0.710744</td>
      <td>0.11157</td>
      <td>0.097107</td>
      <td>0.564777</td>
      <td>0.555556</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="observations">Observations</h4>

<ul>
  <li>
    <p>The accuracy is <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≈</mo><mn>56</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\approx 56\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.48312em;vertical-align:0em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">5</span><span class="mord">6</span><span class="mord">%</span></span></span></span> so the model is right a bit more than half the time</p>
  </li>
  <li>
    <p>The error rate is <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≈</mo><mn>44</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\approx 44\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.48312em;vertical-align:0em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">4</span><span class="mord">4</span><span class="mord">%</span></span></span></span> so the model is wrong a bit less than half the time</p>
  </li>
  <li>
    <p>The “null error rate” is the error rate of the “null classifier” which always predicts the majority class, which in this case is <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≈</mo><mn>56</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\approx 56\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.48312em;vertical-align:0em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">5</span><span class="mord">6</span><span class="mord">%</span></span></span></span>. Thus our model is about as accurate as the null classifier.</p>
  </li>
  <li>
    <p>The true positive and false positive rates are relatively high. The true negative and false negative rates are relatively low. This makes sense – inspection of the confusion matrix shows that the model predicts positives almost an order of magnitude more often</p>
  </li>
  <li>
    <p>The precision is <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≈</mo><mn>56</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\approx 56\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.48312em;vertical-align:0em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">5</span><span class="mord">6</span><span class="mord">%</span></span></span></span> so the model correctly predicts positives a little more than half the time</p>
  </li>
  <li>
    <p>The prevalence is also <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≈</mo><mn>56</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">\approx 56\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.48312em;vertical-align:0em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">5</span><span class="mord">6</span><span class="mord">%</span></span></span></span> so positives occur in the sample a little more than half the time</p>
  </li>
</ul>

<p>We’ll package this functionality for later use:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">confusion_results</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">skl_model_fit</span><span class="p">):</span>
    <span class="c"># get confusion array</span>
    <span class="n">confusion_array</span> <span class="o">=</span> <span class="n">skl_metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">skl_model_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

    <span class="c"># necessary variables</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">confusion_array</span><span class="p">)</span>
    <span class="n">TN</span> <span class="o">=</span> <span class="n">confusion_array</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">FP</span> <span class="o">=</span> <span class="n">confusion_array</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">FN</span> <span class="o">=</span> <span class="n">confusion_array</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_array</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="c"># compute rates</span>
    <span class="n">rates</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">rates</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
    <span class="n">rates</span><span class="p">[</span><span class="s">'error rate'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
    <span class="n">rates</span><span class="p">[</span><span class="s">'null error'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">,</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
    <span class="n">rates</span><span class="p">[</span><span class="s">'TP rate'</span><span class="p">]</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
    <span class="n">rates</span><span class="p">[</span><span class="s">'FP rate'</span><span class="p">]</span> <span class="o">=</span> <span class="n">FP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
    <span class="n">rates</span><span class="p">[</span><span class="s">'TN rate'</span><span class="p">]</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span>
    <span class="n">rates</span><span class="p">[</span><span class="s">'FN rate'</span><span class="p">]</span> <span class="o">=</span> <span class="n">FN</span> <span class="o">/</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span>
    <span class="n">rates</span><span class="p">[</span><span class="s">'precision'</span><span class="p">]</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span>
    <span class="n">rates</span><span class="p">[</span><span class="s">'prevalence'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>


    <span class="c"># return results</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rates</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">confusion_results</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">skl_logit_model_full</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">))</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>accuracy</th>
      <th>error rate</th>
      <th>null error</th>
      <th>TP rate</th>
      <th>FP rate</th>
      <th>TN rate</th>
      <th>FN rate</th>
      <th>precision</th>
      <th>prevalence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.561983</td>
      <td>0.438017</td>
      <td>0.555556</td>
      <td>0.922314</td>
      <td>0.710744</td>
      <td>0.11157</td>
      <td>0.097107</td>
      <td>0.564777</td>
      <td>0.555556</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="d-logistic-regression-classification-of-direction-using-lag2-predictor">d. Logistic Regression Classification of <code class="highlighter-rouge">Direction</code> using <code class="highlighter-rouge">Lag2</code> predictor</h2>

<p>In this section we do some feature selection. Since in b. we found that only <code class="highlighter-rouge">Lag2</code> was a significant feature, we’ll eliminate the others. Further, we’ll train on the years 1990 to 2008 and test on 2009 to 2010</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># train/test split</span>
<span class="n">weekly_test</span><span class="p">,</span> <span class="n">weekly_train</span> <span class="o">=</span> <span class="n">weekly</span><span class="p">[</span><span class="n">weekly</span><span class="p">[</span><span class="s">'Year'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">2008</span><span class="p">],</span> <span class="n">weekly</span><span class="p">[</span><span class="n">weekly</span><span class="p">[</span><span class="s">'Year'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2008</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">weekly_train</span><span class="p">[</span><span class="s">'Lag2'</span><span class="p">]),</span> <span class="n">weekly_train</span><span class="p">[</span><span class="s">'Direction_num'</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">weekly_test</span><span class="p">[</span><span class="s">'Lag2'</span><span class="p">]),</span> <span class="n">weekly_test</span><span class="p">[</span><span class="s">'Direction_num'</span><span class="p">]</span>

<span class="c"># fit new model</span>
<span class="n">skl_logit_model_lag2</span> <span class="o">=</span> <span class="n">skl_linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># confusion matrix</span>
<span class="n">confusion_results</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">skl_logit_model_lag2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>accuracy</th>
      <th>error rate</th>
      <th>null error</th>
      <th>TP rate</th>
      <th>FP rate</th>
      <th>TN rate</th>
      <th>FN rate</th>
      <th>precision</th>
      <th>prevalence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.550254</td>
      <td>0.449746</td>
      <td>0.552284</td>
      <td>0.963235</td>
      <td>0.777574</td>
      <td>0.040816</td>
      <td>0.045351</td>
      <td>0.553326</td>
      <td>0.552284</td>
    </tr>
  </tbody>
</table>
</div>

<p>The accuracy is actually slightly worse than the full model</p>

<h2 id="e--other-classification-models-of-direction-using-lag2-predictor">e.  Other classification models of <code class="highlighter-rouge">Direction</code> using <code class="highlighter-rouge">Lag2</code> predictor</h2>

<h3 id="lda">LDA</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="k">as</span> <span class="n">skl_discriminant_analysis</span>

<span class="n">skl_LDA_model_lag2</span> <span class="o">=</span> <span class="n">skl_discriminant_analysis</span><span class="o">.</span><span class="n">LinearDiscriminantAnalysis</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># confusion matrix</span>
<span class="n">confusion_results</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">skl_LDA_model_lag2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>accuracy</th>
      <th>error rate</th>
      <th>null error</th>
      <th>TP rate</th>
      <th>FP rate</th>
      <th>TN rate</th>
      <th>FN rate</th>
      <th>precision</th>
      <th>prevalence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.550254</td>
      <td>0.449746</td>
      <td>0.552284</td>
      <td>0.965074</td>
      <td>0.779412</td>
      <td>0.038549</td>
      <td>0.043084</td>
      <td>0.553214</td>
      <td>0.552284</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># accuracy</span>
<span class="n">skl_metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">skl_LDA_model_lag2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.550253807106599
</code></pre></div></div>

<p>Nearly identical to <code class="highlighter-rouge">skl_logit_model_lag2</code>!</p>

<h3 id="qda">QDA</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">skl_QDA_model_lag2</span> <span class="o">=</span> <span class="n">skl_discriminant_analysis</span><span class="o">.</span><span class="n">QuadraticDiscriminantAnalysis</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># confusion matrix</span>
<span class="n">confusion_results</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">skl_QDA_model_lag2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>accuracy</th>
      <th>error rate</th>
      <th>null error</th>
      <th>TP rate</th>
      <th>FP rate</th>
      <th>TN rate</th>
      <th>FN rate</th>
      <th>precision</th>
      <th>prevalence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.447716</td>
      <td>0.552284</td>
      <td>0.552284</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.23356</td>
      <td>NaN</td>
      <td>0.552284</td>
    </tr>
  </tbody>
</table>
</div>

<p>Worse accuracy than Logistic Regression and LDA</p>

<h3 id="knn">KNN</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sklearn.neighbors</span> <span class="k">as</span> <span class="n">skl_neighbors</span>

<span class="n">skl_KNN_model_lag2</span> <span class="o">=</span> <span class="n">skl_neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># confusion matrix</span>
<span class="n">confusion_results</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">skl_KNN_model_lag2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>accuracy</th>
      <th>error rate</th>
      <th>null error</th>
      <th>TP rate</th>
      <th>FP rate</th>
      <th>TN rate</th>
      <th>FN rate</th>
      <th>precision</th>
      <th>prevalence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.518782</td>
      <td>0.481218</td>
      <td>0.552284</td>
      <td>0.626838</td>
      <td>0.498162</td>
      <td>0.385488</td>
      <td>0.460317</td>
      <td>0.55719</td>
      <td>0.552284</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="comparing-results">Comparing results</h3>

<p>For neatness and ease of comparison, we’ll package all these results</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">confusion_comparison</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">models</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">confusion_results</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">])</span> 
                      <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">models</span><span class="p">])</span>
    <span class="n">df</span><span class="p">[</span><span class="s">'Model'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'Model'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models</span> <span class="o">=</span> <span class="p">{</span><span class="s">'Logit'</span><span class="p">:</span> <span class="n">skl_logit_model_lag2</span><span class="p">,</span> <span class="s">'LDA'</span><span class="p">:</span> <span class="n">skl_LDA_model_lag2</span><span class="p">,</span> 
          <span class="s">'QDA'</span><span class="p">:</span> <span class="n">skl_QDA_model_lag2</span><span class="p">,</span> <span class="s">'KNN'</span><span class="p">:</span> <span class="n">skl_KNN_model_lag2</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">conf_comp_df</span> <span class="o">=</span> <span class="n">confusion_comparison</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">models</span><span class="p">)</span>
<span class="n">conf_comp_df</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>accuracy</th>
      <th>error rate</th>
      <th>null error</th>
      <th>TP rate</th>
      <th>FP rate</th>
      <th>TN rate</th>
      <th>FN rate</th>
      <th>precision</th>
      <th>prevalence</th>
    </tr>
    <tr>
      <th>Model</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Logit</th>
      <td>0.550254</td>
      <td>0.449746</td>
      <td>0.552284</td>
      <td>0.963235</td>
      <td>0.777574</td>
      <td>0.040816</td>
      <td>0.045351</td>
      <td>0.553326</td>
      <td>0.552284</td>
    </tr>
    <tr>
      <th>LDA</th>
      <td>0.550254</td>
      <td>0.449746</td>
      <td>0.552284</td>
      <td>0.965074</td>
      <td>0.779412</td>
      <td>0.038549</td>
      <td>0.043084</td>
      <td>0.553214</td>
      <td>0.552284</td>
    </tr>
    <tr>
      <th>QDA</th>
      <td>0.447716</td>
      <td>0.552284</td>
      <td>0.552284</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.233560</td>
      <td>NaN</td>
      <td>0.552284</td>
    </tr>
    <tr>
      <th>KNN</th>
      <td>0.518782</td>
      <td>0.481218</td>
      <td>0.552284</td>
      <td>0.626838</td>
      <td>0.498162</td>
      <td>0.385488</td>
      <td>0.460317</td>
      <td>0.557190</td>
      <td>0.552284</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="h-which-method-has-the-best-results">h. Which method has the best results?</h2>

<p>As measured by accuracy, Logit and LDA models are tied, with KNN not too far behind and QDA a more distant third.</p>

<p>With respect to other confusion metrics, Logit and LDA are nearly identical</p>

<h2 id="i-feature-and-model-selection">i. Feature and Model Selection</h2>

<p>In this section, we’ll experiment to try to find improved performance on the test data. We’ll try:</p>

<ul>
  <li>Different subsets of the predictors</li>
  <li>Interactions among the predictors</li>
  <li>Transformations of the predictors</li>
  <li>Different values of <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> for KNN</li>
</ul>

<h3 id="get-all-predictor-interactions">Get all predictor interactions</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>

<span class="c"># all pairs of columns in weekly except year and direction</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">weekly</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Year'</span><span class="p">,</span> <span class="s">'Direction'</span><span class="p">,</span> <span class="s">'Direction_num'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">col_pairs</span> <span class="o">=</span> <span class="n">combinations</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c"># assemble interactions in dataframe</span>
<span class="n">interaction_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="n">col1</span> <span class="o">+</span> <span class="s">':'</span> <span class="o">+</span> <span class="n">col2</span><span class="p">:</span> <span class="n">weekly</span><span class="p">[</span><span class="n">col1</span><span class="p">]</span><span class="o">*</span><span class="n">weekly</span><span class="p">[</span><span class="n">col2</span><span class="p">]</span> 
                               <span class="k">for</span> <span class="p">(</span><span class="n">col1</span><span class="p">,</span> <span class="n">col2</span><span class="p">)</span> <span class="ow">in</span> <span class="n">col_pairs</span><span class="p">})</span>

<span class="c"># concat data frames</span>
<span class="n">dir_df</span> <span class="o">=</span> <span class="n">weekly</span><span class="p">[[</span><span class="s">'Direction'</span><span class="p">,</span> <span class="s">'Direction_num'</span><span class="p">]]</span>
<span class="n">weekly_interact</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">weekly</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Direction'</span><span class="p">,</span> <span class="s">'Direction_num'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                             <span class="n">interaction_df</span><span class="p">,</span> <span class="n">dir_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">weekly_interact</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>Year</th>
      <th>Lag1</th>
      <th>Lag2</th>
      <th>Lag3</th>
      <th>Lag4</th>
      <th>Lag5</th>
      <th>Volume</th>
      <th>Today</th>
      <th>Lag1:Lag2</th>
      <th>Lag1:Lag3</th>
      <th>...</th>
      <th>Lag3:Volume</th>
      <th>Lag3:Today</th>
      <th>Lag4:Lag5</th>
      <th>Lag4:Volume</th>
      <th>Lag4:Today</th>
      <th>Lag5:Volume</th>
      <th>Lag5:Today</th>
      <th>Volume:Today</th>
      <th>Direction</th>
      <th>Direction_num</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1990</td>
      <td>0.816</td>
      <td>1.572</td>
      <td>-3.936</td>
      <td>-0.229</td>
      <td>-3.484</td>
      <td>0.154976</td>
      <td>-0.270</td>
      <td>1.282752</td>
      <td>-3.211776</td>
      <td>...</td>
      <td>-0.609986</td>
      <td>1.062720</td>
      <td>0.797836</td>
      <td>-0.035490</td>
      <td>0.061830</td>
      <td>-0.539936</td>
      <td>0.940680</td>
      <td>-0.041844</td>
      <td>Down</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1990</td>
      <td>-0.270</td>
      <td>0.816</td>
      <td>1.572</td>
      <td>-3.936</td>
      <td>-0.229</td>
      <td>0.148574</td>
      <td>-2.576</td>
      <td>-0.220320</td>
      <td>-0.424440</td>
      <td>...</td>
      <td>0.233558</td>
      <td>-4.049472</td>
      <td>0.901344</td>
      <td>-0.584787</td>
      <td>10.139136</td>
      <td>-0.034023</td>
      <td>0.589904</td>
      <td>-0.382727</td>
      <td>Down</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1990</td>
      <td>-2.576</td>
      <td>-0.270</td>
      <td>0.816</td>
      <td>1.572</td>
      <td>-3.936</td>
      <td>0.159837</td>
      <td>3.514</td>
      <td>0.695520</td>
      <td>-2.102016</td>
      <td>...</td>
      <td>0.130427</td>
      <td>2.867424</td>
      <td>-6.187392</td>
      <td>0.251265</td>
      <td>5.524008</td>
      <td>-0.629120</td>
      <td>-13.831104</td>
      <td>0.561669</td>
      <td>Up</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1990</td>
      <td>3.514</td>
      <td>-2.576</td>
      <td>-0.270</td>
      <td>0.816</td>
      <td>1.572</td>
      <td>0.161630</td>
      <td>0.712</td>
      <td>-9.052064</td>
      <td>-0.948780</td>
      <td>...</td>
      <td>-0.043640</td>
      <td>-0.192240</td>
      <td>1.282752</td>
      <td>0.131890</td>
      <td>0.580992</td>
      <td>0.254082</td>
      <td>1.119264</td>
      <td>0.115081</td>
      <td>Up</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1990</td>
      <td>0.712</td>
      <td>3.514</td>
      <td>-2.576</td>
      <td>-0.270</td>
      <td>0.816</td>
      <td>0.153728</td>
      <td>1.178</td>
      <td>2.501968</td>
      <td>-1.834112</td>
      <td>...</td>
      <td>-0.396003</td>
      <td>-3.034528</td>
      <td>-0.220320</td>
      <td>-0.041507</td>
      <td>-0.318060</td>
      <td>0.125442</td>
      <td>0.961248</td>
      <td>0.181092</td>
      <td>Up</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
  <p>5 rows × 31 columns</p>
</div>

<h3 id="choose-some-transformations">Choose some transformations</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># list of transformations</span>

<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">sin</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">exp</span><span class="p">,</span> <span class="n">power</span>

<span class="c"># power functions with odd exponent to preserve sign of inputs</span>
<span class="k">def</span> <span class="nf">power_3</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">power_5</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">power_7</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="c"># transformations are functions with domain all real numbers</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span><span class="n">power_3</span><span class="p">,</span> <span class="n">power_5</span><span class="p">,</span> <span class="n">power_7</span><span class="p">,</span> <span class="n">sin</span><span class="p">,</span> <span class="n">exp</span><span class="p">]</span>
<span class="n">transforms</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;function __main__.power_3(array)&gt;,
 &lt;function __main__.power_5(array)&gt;,
 &lt;function __main__.power_7(array)&gt;,
 &lt;ufunc 'sin'&gt;,
 &lt;ufunc 'exp'&gt;]
</code></pre></div></div>

<h3 id="random-data-tweak">Random data tweak</h3>

<p>We’ll write a simple function which returns a dataset which has</p>

<ul>
  <li>as predictors a random subset of the predictors and interactions of the original dataset (i.e. a random subset of the columns of <code class="highlighter-rouge">weekly_interact</code>)</li>
  <li>a random subset of its predictors transformed by a random choice of transformations from <code class="highlighter-rouge">transform</code></li>
</ul>

<p>We call such a dataset a “random data tweak”</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">random_data_tweak</span><span class="p">(</span><span class="n">weekly_interact</span><span class="p">,</span> <span class="n">transforms</span><span class="p">):</span>
    <span class="c"># drop undersirable columns</span>
    <span class="n">weekly_drop</span> <span class="o">=</span> <span class="n">weekly_interact</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Year'</span><span class="p">,</span> <span class="s">'Direction'</span><span class="p">,</span> <span class="s">'Direction_num'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c"># choose a random subset of the predictors</span>
    <span class="n">predictor_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">weekly_drop</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> 
                                  <span class="n">size</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">weekly_drop</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
                                  <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>


    <span class="c"># choose a random subset of these to transform</span>
    <span class="n">trans_predictor_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">predictor_labels</span><span class="p">,</span> 
                                          <span class="n">size</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictor_labels</span><span class="p">)),</span>
                                          <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="c"># choose random transforms</span>
    <span class="n">some_transforms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">transforms</span><span class="p">,</span>
                                  <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">trans_predictor_labels</span><span class="p">),</span>
                                  <span class="n">replace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c"># create the df</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">weekly_interact</span><span class="p">[</span><span class="n">predictor_labels</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="c"># transform appropriate columns</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trans_predictor_labels</span><span class="p">)):</span>
        <span class="c"># do transformation</span>
        <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span> <span class="p">:</span> <span class="p">,</span> <span class="n">trans_predictor_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">some_transforms</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">df</span><span class="p">[</span><span class="n">trans_predictor_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
        <span class="c"># rename to reflect which transformation was used</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="n">trans_predictor_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> 
                    <span class="n">some_transforms</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">__name__</span> <span class="o">+</span> <span class="s">'('</span> <span class="o">+</span> <span class="n">trans_predictor_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s">')'</span> <span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="s">'columns'</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">weekly_interact</span><span class="p">[</span><span class="s">'Direction_num'</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">random_data_tweak</span><span class="p">(</span><span class="n">weekly_interact</span><span class="p">,</span> <span class="n">transforms</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>Lag3-Lag5</th>
      <th>power_7(Volume-Today)</th>
      <th>power_5(Lag5)</th>
      <th>Lag2-Lag5</th>
      <th>power_3(Lag4-Lag5)</th>
      <th>sin(Lag4)</th>
      <th>Lag2-Today</th>
      <th>exp(Lag1-Lag5)</th>
      <th>Lag1</th>
      <th>power_5(Lag4-Volume)</th>
      <th>exp(Lag1-Today)</th>
      <th>Lag4-Today</th>
      <th>sin(Lag5-Volume)</th>
      <th>Lag3-Today</th>
      <th>power_3(Lag3-Lag4)</th>
      <th>exp(Lag2)</th>
      <th>Direction_num</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>13.713024</td>
      <td>0.000003</td>
      <td>-42.289684</td>
      <td>-5.476848</td>
      <td>0.507856</td>
      <td>-0.227004</td>
      <td>-0.424440</td>
      <td>0.058254</td>
      <td>0.816</td>
      <td>-0.000045</td>
      <td>0.802262</td>
      <td>0.061830</td>
      <td>-0.514081</td>
      <td>1.062720</td>
      <td>0.732271</td>
      <td>4.816271</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.359988</td>
      <td>0.021456</td>
      <td>-0.012009</td>
      <td>-0.186864</td>
      <td>0.732271</td>
      <td>0.713448</td>
      <td>-2.102016</td>
      <td>1.063781</td>
      <td>-0.270</td>
      <td>-0.199983</td>
      <td>2.004751</td>
      <td>10.139136</td>
      <td>-0.034017</td>
      <td>-4.049472</td>
      <td>-236.877000</td>
      <td>2.261436</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-3.211776</td>
      <td>0.099523</td>
      <td>-60.976890</td>
      <td>1.062720</td>
      <td>-236.877000</td>
      <td>0.999999</td>
      <td>-0.948780</td>
      <td>25314.585232</td>
      <td>-2.576</td>
      <td>0.015863</td>
      <td>0.000117</td>
      <td>5.524008</td>
      <td>-0.588434</td>
      <td>2.867424</td>
      <td>2.110708</td>
      <td>0.763379</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.424440</td>
      <td>0.000175</td>
      <td>3.884701</td>
      <td>-4.049472</td>
      <td>2.110708</td>
      <td>0.728411</td>
      <td>-1.834112</td>
      <td>250.637582</td>
      <td>3.514</td>
      <td>0.002294</td>
      <td>12.206493</td>
      <td>0.580992</td>
      <td>0.251357</td>
      <td>-0.192240</td>
      <td>-0.010695</td>
      <td>0.076078</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-2.102016</td>
      <td>0.001075</td>
      <td>0.543338</td>
      <td>2.867424</td>
      <td>-0.010695</td>
      <td>-0.266731</td>
      <td>4.139492</td>
      <td>1.787811</td>
      <td>0.712</td>
      <td>-0.000072</td>
      <td>2.313441</td>
      <td>-0.318060</td>
      <td>0.125113</td>
      <td>-3.034528</td>
      <td>0.336456</td>
      <td>33.582329</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="comparison-of-logit-lda-qda-and-knn-models-on-a-single-random-data-tweak">Comparison of Logit, LDA, QDA, and KNN models on a single random data tweak</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sklearn.model_selection</span> <span class="k">as</span> <span class="n">skl_model_selection</span>

<span class="k">def</span> <span class="nf">model_comparison</span><span class="p">():</span>
    <span class="c"># tweak data</span>
    <span class="n">tweak_df</span> <span class="o">=</span> <span class="n">random_data_tweak</span><span class="p">(</span><span class="n">weekly_interact</span><span class="p">,</span> <span class="n">transforms</span><span class="p">)</span>
    
    <span class="c"># train test split</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">tweak_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Direction_num'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">),</span> <span class="n">tweak_df</span><span class="p">[</span><span class="s">'Direction_num'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">skl_model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="c"># dict for models</span>
    <span class="n">models</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c"># train param models</span>
    <span class="n">models</span><span class="p">[</span><span class="s">'Logit'</span><span class="p">]</span> <span class="o">=</span> <span class="n">skl_linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s">'lbfgs'</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">models</span><span class="p">[</span><span class="s">'LDA'</span><span class="p">]</span> <span class="o">=</span> <span class="n">skl_discriminant_analysis</span><span class="o">.</span><span class="n">LinearDiscriminantAnalysis</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">models</span><span class="p">[</span><span class="s">'QDA'</span><span class="p">]</span> <span class="o">=</span>  <span class="n">skl_discriminant_analysis</span><span class="o">.</span><span class="n">QuadraticDiscriminantAnalysis</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c"># train KNN models for K = 1,..,5</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">):</span>
        <span class="n">models</span><span class="p">[</span><span class="s">'KNN'</span> <span class="o">+</span> <span class="n">stri</span><span class="o">.</span><span class="p">]</span> <span class="o">=</span> <span class="n">skl_neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    
    <span class="k">return</span> <span class="p">{</span><span class="s">'predictors'</span><span class="p">:</span> <span class="n">tweak_df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s">'comparison'</span><span class="p">:</span> <span class="n">confusion_comparison</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">models</span><span class="p">)}</span>    
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_comparison</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="comparison-of-logit-lda-qda-and-knn-models-over-nnn-data-tweaks">Comparison of Logit, LDA, QDA, and KNN models over <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span> data tweaks</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">model_comparisons</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c"># running list of predictors and dfs from each comparison</span>
    <span class="n">predictors_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">dfs</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c"># iterate comparisons</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="c"># get comparison result</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model_comparison</span><span class="p">()</span>
        <span class="n">predictors_list</span> <span class="o">+=</span> <span class="p">[</span><span class="n">result</span><span class="p">[</span><span class="s">'predictors'</span><span class="p">]]</span>
        
        <span class="c"># set MultiIndex</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s">'comparison'</span><span class="p">]</span>
        <span class="n">df</span><span class="p">[</span><span class="s">'Instance'</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
        <span class="n">df</span>  <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s">'Instance'</span><span class="p">,</span> <span class="s">'Model'</span><span class="p">])</span>
        
        <span class="c"># add results to running lists</span>
        <span class="n">dfs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">df</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="p">{</span><span class="s">'predictors'</span><span class="p">:</span> <span class="n">predictors_list</span><span class="p">,</span> <span class="s">'comparisons'</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">dfs</span><span class="p">)}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="n">model_comparisons</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></div>

<p>Here are the first 3 comparisons:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">comparisons_df</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s">'comparisons'</span><span class="p">]</span>
<span class="n">comparisons_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">21</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th></th>
      <th>accuracy</th>
      <th>error rate</th>
      <th>null error</th>
      <th>TP rate</th>
      <th>FP rate</th>
      <th>TN rate</th>
      <th>FN rate</th>
      <th>precision</th>
      <th>prevalence</th>
    </tr>
    <tr>
      <th>Instance</th>
      <th>Model</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="8" valigned="top">0</th>
      <th>Logit</th>
      <td>0.560440</td>
      <td>0.439560</td>
      <td>0.549451</td>
      <td>0.666667</td>
      <td>0.466667</td>
      <td>0.430894</td>
      <td>0.406504</td>
      <td>0.588235</td>
      <td>0.549451</td>
    </tr>
    <tr>
      <th>LDA</th>
      <td>0.948718</td>
      <td>0.051282</td>
      <td>0.549451</td>
      <td>1.000000</td>
      <td>0.093333</td>
      <td>0.886179</td>
      <td>0.000000</td>
      <td>0.914634</td>
      <td>0.549451</td>
    </tr>
    <tr>
      <th>QDA</th>
      <td>0.450549</td>
      <td>0.549451</td>
      <td>0.549451</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.219512</td>
      <td>NaN</td>
      <td>0.549451</td>
    </tr>
    <tr>
      <th>KNN1</th>
      <td>0.714286</td>
      <td>0.285714</td>
      <td>0.549451</td>
      <td>0.760000</td>
      <td>0.280000</td>
      <td>0.658537</td>
      <td>0.292683</td>
      <td>0.730769</td>
      <td>0.549451</td>
    </tr>
    <tr>
      <th>KNN2</th>
      <td>0.688645</td>
      <td>0.311355</td>
      <td>0.549451</td>
      <td>0.553333</td>
      <td>0.120000</td>
      <td>0.853659</td>
      <td>0.544715</td>
      <td>0.821782</td>
      <td>0.549451</td>
    </tr>
    <tr>
      <th>KNN3</th>
      <td>0.703297</td>
      <td>0.296703</td>
      <td>0.549451</td>
      <td>0.740000</td>
      <td>0.280000</td>
      <td>0.658537</td>
      <td>0.317073</td>
      <td>0.725490</td>
      <td>0.549451</td>
    </tr>
    <tr>
      <th>KNN4</th>
      <td>0.699634</td>
      <td>0.300366</td>
      <td>0.549451</td>
      <td>0.653333</td>
      <td>0.200000</td>
      <td>0.756098</td>
      <td>0.422764</td>
      <td>0.765625</td>
      <td>0.549451</td>
    </tr>
    <tr>
      <th>KNN5</th>
      <td>0.703297</td>
      <td>0.296703</td>
      <td>0.549451</td>
      <td>0.760000</td>
      <td>0.300000</td>
      <td>0.634146</td>
      <td>0.292683</td>
      <td>0.716981</td>
      <td>0.549451</td>
    </tr>
    <tr>
      <th rowspan="8" valigned="top">1</th>
      <th>Logit</th>
      <td>0.937729</td>
      <td>0.062271</td>
      <td>0.523810</td>
      <td>0.979021</td>
      <td>0.097902</td>
      <td>0.892308</td>
      <td>0.023077</td>
      <td>0.909091</td>
      <td>0.523810</td>
    </tr>
    <tr>
      <th>LDA</th>
      <td>0.695971</td>
      <td>0.304029</td>
      <td>0.523810</td>
      <td>0.965035</td>
      <td>0.545455</td>
      <td>0.400000</td>
      <td>0.038462</td>
      <td>0.638889</td>
      <td>0.523810</td>
    </tr>
    <tr>
      <th>QDA</th>
      <td>0.476190</td>
      <td>0.523810</td>
      <td>0.523810</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.100000</td>
      <td>NaN</td>
      <td>0.523810</td>
    </tr>
    <tr>
      <th>KNN1</th>
      <td>0.706960</td>
      <td>0.293040</td>
      <td>0.523810</td>
      <td>0.769231</td>
      <td>0.328671</td>
      <td>0.638462</td>
      <td>0.253846</td>
      <td>0.700637</td>
      <td>0.523810</td>
    </tr>
    <tr>
      <th>KNN2</th>
      <td>0.710623</td>
      <td>0.289377</td>
      <td>0.523810</td>
      <td>0.587413</td>
      <td>0.139860</td>
      <td>0.846154</td>
      <td>0.453846</td>
      <td>0.807692</td>
      <td>0.523810</td>
    </tr>
    <tr>
      <th>KNN3</th>
      <td>0.706960</td>
      <td>0.293040</td>
      <td>0.523810</td>
      <td>0.790210</td>
      <td>0.349650</td>
      <td>0.615385</td>
      <td>0.230769</td>
      <td>0.693252</td>
      <td>0.523810</td>
    </tr>
    <tr>
      <th>KNN4</th>
      <td>0.695971</td>
      <td>0.304029</td>
      <td>0.523810</td>
      <td>0.650350</td>
      <td>0.230769</td>
      <td>0.746154</td>
      <td>0.384615</td>
      <td>0.738095</td>
      <td>0.523810</td>
    </tr>
    <tr>
      <th>KNN5</th>
      <td>0.725275</td>
      <td>0.274725</td>
      <td>0.523810</td>
      <td>0.825175</td>
      <td>0.349650</td>
      <td>0.615385</td>
      <td>0.192308</td>
      <td>0.702381</td>
      <td>0.523810</td>
    </tr>
    <tr>
      <th rowspan="5" valigned="top">2</th>
      <th>Logit</th>
      <td>0.454212</td>
      <td>0.545788</td>
      <td>0.545788</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.201613</td>
      <td>NaN</td>
      <td>0.545788</td>
    </tr>
    <tr>
      <th>LDA</th>
      <td>0.967033</td>
      <td>0.032967</td>
      <td>0.545788</td>
      <td>0.959732</td>
      <td>0.020134</td>
      <td>0.975806</td>
      <td>0.048387</td>
      <td>0.979452</td>
      <td>0.545788</td>
    </tr>
    <tr>
      <th>QDA</th>
      <td>0.454212</td>
      <td>0.545788</td>
      <td>0.545788</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.201613</td>
      <td>NaN</td>
      <td>0.545788</td>
    </tr>
    <tr>
      <th>KNN1</th>
      <td>0.501832</td>
      <td>0.498168</td>
      <td>0.545788</td>
      <td>0.510067</td>
      <td>0.422819</td>
      <td>0.491935</td>
      <td>0.588710</td>
      <td>0.546763</td>
      <td>0.545788</td>
    </tr>
    <tr>
      <th>KNN2</th>
      <td>0.487179</td>
      <td>0.512821</td>
      <td>0.545788</td>
      <td>0.308725</td>
      <td>0.248322</td>
      <td>0.701613</td>
      <td>0.830645</td>
      <td>0.554217</td>
      <td>0.545788</td>
    </tr>
  </tbody>
</table>
</div>

<p>Here are the predictors used for the first 3 comparisons:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictors_list</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s">'predictors'</span><span class="p">]</span>

<span class="n">predictors_list</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Index(['Lag2-Today', 'Lag4-Volume', 'Lag2-Lag3', 'Volume-Today', 'Lag2',
        'power_7(Lag1-Volume)', 'Lag1-Lag2', 'Lag2-Volume', 'Lag4-Today',
        'sin(Lag3-Today)', 'Lag3-Lag4', 'Lag5-Volume', 'Today',
        'power_5(Lag3-Lag5)', 'Lag1-Lag5', 'Lag4', 'Direction_num'],
       dtype='object'),
 Index(['Lag3-Lag5', 'Lag5-Today', 'Lag1', 'sin(Lag2-Volume)', 'Lag2-Today',
        'power_5(Volume)', 'Lag4-Lag5', 'Lag1-Lag2', 'power_5(Lag2-Lag3)',
        'Lag3-Today', 'Lag3-Volume', 'Volume-Today', 'Lag1-Today',
        'Direction_num'],
       dtype='object'),
 Index(['power_3(Lag2-Lag3)', 'Lag1-Today', 'Lag4-Volume', 'sin(Lag1-Lag2)',
        'power_7(Lag2-Today)', 'Lag1', 'exp(Lag2-Lag4)', 'power_3(Volume)',
        'exp(Lag3-Lag5)', 'exp(Lag5)', 'power_5(Lag1-Lag5)', 'Today',
        'Lag1-Lag3', 'Lag4-Today', 'power_5(Lag5-Today)', 'exp(Lag3-Lag4)',
        'power_7(Lag3-Today)', 'sin(Lag2)', 'sin(Volume-Today)',
        'power_3(Lag2-Volume)', 'Lag1-Lag4', 'power_7(Lag4-Lag5)',
        'exp(Lag5-Volume)', 'Direction_num'],
       dtype='object')]
</code></pre></div></div>

<h3 id="analysis-of-comparisons">Analysis of Comparisons</h3>

<h4 id="analyzing-accuracy-across-models">Analyzing accuracy across models</h4>

<h5 id="summary-statistics">Summary statistics</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grouped_by_model</span> <span class="o">=</span> <span class="n">comparisons_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">grouped_by_model</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>accuracy</th>
      <th>error rate</th>
      <th>null error</th>
      <th>TP rate</th>
      <th>FP rate</th>
      <th>TN rate</th>
      <th>FN rate</th>
      <th>precision</th>
      <th>prevalence</th>
    </tr>
    <tr>
      <th>Model</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>KNN1</th>
      <td>0.626147</td>
      <td>0.373853</td>
      <td>0.556381</td>
      <td>0.668314</td>
      <td>0.342757</td>
      <td>0.574424</td>
      <td>0.418527</td>
      <td>0.662625</td>
      <td>0.55615</td>
    </tr>
    <tr>
      <th>KNN2</th>
      <td>0.601912</td>
      <td>0.398088</td>
      <td>0.556381</td>
      <td>0.463810</td>
      <td>0.180901</td>
      <td>0.775631</td>
      <td>0.676137</td>
      <td>0.707457</td>
      <td>0.55615</td>
    </tr>
    <tr>
      <th>KNN3</th>
      <td>0.629945</td>
      <td>0.370055</td>
      <td>0.556381</td>
      <td>0.690867</td>
      <td>0.358510</td>
      <td>0.555069</td>
      <td>0.390503</td>
      <td>0.661137</td>
      <td>0.55615</td>
    </tr>
    <tr>
      <th>KNN4</th>
      <td>0.615769</td>
      <td>0.384231</td>
      <td>0.556381</td>
      <td>0.544830</td>
      <td>0.237261</td>
      <td>0.705825</td>
      <td>0.574505</td>
      <td>0.691635</td>
      <td>0.55615</td>
    </tr>
    <tr>
      <th>KNN5</th>
      <td>0.631011</td>
      <td>0.368989</td>
      <td>0.556381</td>
      <td>0.706117</td>
      <td>0.371881</td>
      <td>0.538619</td>
      <td>0.371593</td>
      <td>0.658446</td>
      <td>0.55615</td>
    </tr>
    <tr>
      <th>LDA</th>
      <td>0.726355</td>
      <td>0.273645</td>
      <td>0.556381</td>
      <td>0.942929</td>
      <td>0.437290</td>
      <td>0.456703</td>
      <td>0.073307</td>
      <td>0.717898</td>
      <td>0.55615</td>
    </tr>
    <tr>
      <th>Logit</th>
      <td>0.551216</td>
      <td>0.448784</td>
      <td>0.556381</td>
      <td>0.368049</td>
      <td>0.176416</td>
      <td>0.782584</td>
      <td>0.797881</td>
      <td>0.697051</td>
      <td>0.55615</td>
    </tr>
    <tr>
      <th>QDA</th>
      <td>0.462040</td>
      <td>0.537960</td>
      <td>0.556381</td>
      <td>0.085262</td>
      <td>0.053065</td>
      <td>0.933012</td>
      <td>1.151742</td>
      <td>0.619088</td>
      <td>0.55615</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grouped_by_model</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model
LDA      0.726355
KNN5     0.631011
KNN3     0.629945
KNN1     0.626147
KNN4     0.615769
KNN2     0.601912
Logit    0.551216
QDA      0.462040
Name: accuracy, dtype: float64
</code></pre></div></div>

<p>Let’s look at summary statistics for accuracy</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grouped_by_model</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-aligned: middle;
    }

    .dataframe tbody tr th {
        vertical-aligned: top;
    }

    .dataframe thead th {
        text-aligned: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-aligned: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>Model</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>KNN1</th>
      <td>1000.0</td>
      <td>0.626147</td>
      <td>0.111154</td>
      <td>0.435897</td>
      <td>0.545788</td>
      <td>0.600733</td>
      <td>0.684982</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>KNN2</th>
      <td>1000.0</td>
      <td>0.601912</td>
      <td>0.112694</td>
      <td>0.421245</td>
      <td>0.516484</td>
      <td>0.578755</td>
      <td>0.659341</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>KNN3</th>
      <td>1000.0</td>
      <td>0.629945</td>
      <td>0.110973</td>
      <td>0.443223</td>
      <td>0.549451</td>
      <td>0.604396</td>
      <td>0.682234</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>KNN4</th>
      <td>1000.0</td>
      <td>0.615769</td>
      <td>0.113840</td>
      <td>0.410256</td>
      <td>0.531136</td>
      <td>0.589744</td>
      <td>0.670330</td>
      <td>0.996337</td>
    </tr>
    <tr>
      <th>KNN5</th>
      <td>1000.0</td>
      <td>0.631011</td>
      <td>0.112222</td>
      <td>0.439560</td>
      <td>0.549451</td>
      <td>0.600733</td>
      <td>0.692308</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>LDA</th>
      <td>1000.0</td>
      <td>0.726355</td>
      <td>0.177813</td>
      <td>0.476190</td>
      <td>0.556777</td>
      <td>0.699634</td>
      <td>0.941392</td>
      <td>0.996337</td>
    </tr>
    <tr>
      <th>Logit</th>
      <td>1000.0</td>
      <td>0.551216</td>
      <td>0.186576</td>
      <td>0.369963</td>
      <td>0.439560</td>
      <td>0.468864</td>
      <td>0.553114</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>QDA</th>
      <td>1000.0</td>
      <td>0.462040</td>
      <td>0.072413</td>
      <td>0.369963</td>
      <td>0.428571</td>
      <td>0.446886</td>
      <td>0.468864</td>
      <td>0.967033</td>
    </tr>
  </tbody>
</table>
</div>

<p>Interesting – all models were able to get very close to or achieve 100% accuracy at least once.</p>

<p><em>TO DO: Try to find similarities in predictors/transformations for the instances which gave maximum classification accuracy</em></p>

<p>Let’s look at some distributions.</p>

<h5 id="distributions-of-accuracy-across-models">Distributions of accuracy across models</h5>

<h6 id="parametric-models">Parametric models</h6>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">'white'</span><span class="p">)</span>

<span class="n">param_models</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Logit'</span><span class="p">,</span> <span class="s">'LDA'</span><span class="p">,</span> <span class="s">'QDA'</span><span class="p">]</span>

<span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">param_models</span><span class="p">:</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">grouped_by_model</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="n">model_name</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.legend.Legend at 0x1a254db860&gt;
</code></pre></div></div>

<p><img src="/islr/assets/images/ch04_exercise_10_105_1.png" alt="png" /></p>

<p>Observations</p>

<ul>
  <li>There are some interesting peaks here – the distributions look bimodal.</li>
  <li>Both Logit and QDA models are highly concentrated in low accuracy, but LDA is more spread out</li>
</ul>

<p><em>TO DO: Try to find similarities in predictors/transformations for the instances clustered around these two modes</em></p>

<h6 id="knn-models">KNN models</h6>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">grouped_by_model</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'KNN1'</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'KNN1'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.legend.Legend at 0x1a252924a8&gt;
</code></pre></div></div>

<p><img src="/islr/assets/images/ch04_exercise_10_108_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">grouped_by_model</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'KNN2'</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'KNN2'</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a2a6e6940&gt;
</code></pre></div></div>

<p><img src="/islr/assets/images/ch04_exercise_10_109_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">grouped_by_model</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'KNN3'</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'KNN3'</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a25ce2cc0&gt;
</code></pre></div></div>

<p><img src="/islr/assets/images/ch04_exercise_10_110_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">grouped_by_model</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'KNN4'</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'KNN4'</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a2569ad30&gt;
</code></pre></div></div>

<p><img src="/islr/assets/images/ch04_exercise_10_111_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">grouped_by_model</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'KNN5'</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'KNN5'</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a25ca3dd8&gt;
</code></pre></div></div>

<p><img src="/islr/assets/images/ch04_exercise_10_112_1.png" alt="png" /></p>

<p>The distributions are all very similar, although they appear to become more concentrated as <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span> increases.</p>


</div>

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', functione. {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
