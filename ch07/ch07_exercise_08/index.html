<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      7. Moving Beyond Linearity &middot; islr
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/islr/public/css/poole.css">
  <link rel="stylesheet" href="/islr/public/css/syntax.css">
  <link rel="stylesheet" href="/islr/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/islr/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/islr/public/favicon.ico">
  --->

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!--- KaTeX --->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
      onload="renderMathInElement(document.body);"></script>
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/islr/">Home</a>

    
    
      
    
      
        
      
    
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch02/">2. Statistical Learning</a>
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch03/">3. Linear Regression</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch04/">4. Logistic Regression</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch05/">5. Resampling Methods</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch06/">6. Linear Model Selection and Regularization</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch07/">7. Moving Beyond Linearity</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch08/">8. Tree-Based Methods</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch09/">9. Support Vector Machines</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          
          <a class="sidebar-nav-item" href="/islr/ch10/">10. Unsupervised Learning</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
    
      
    
      
    
      
    

  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2019.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/islr/" title="Home">islr</a>
            <small>notes and exercises from An Introduction to Statistical Learning</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="page">
  <h1 class="page-title">7. Moving Beyond Linearity</h1>
  	
<h1 id="exercise-8-investigating-non-linear-relationships-in-auto-dataset">Exercise 8: Investigating non-linear relationships in <code class="highlighter-rouge">Auto</code> dataset</h1>

<div class="toc">
  <ul class="toc-item"><li><span><a href="#preparing-the-data" data-toc-modified-id="Preparing-the-data-1">Preparing the data</a></span><ul class="toc-item"><li><span><a href="#import" data-toc-modified-id="Import-1.1">Import</a></span></li><li><span><a href="#encode-categorical-variables" data-toc-modified-id="Encode-categorical-variables-1.2">Encode categorical variables</a></span></li></ul></li><li><span><a href="#inspecting-the-data" data-toc-modified-id="Inspecting-the-Data-2">Inspecting the Data</a></span></li><li><span><a href="#modeling-some-non-linear-relationships-with-mpg" data-toc-modified-id="Modeling-some-non-linear-relationships-with-mpg-3">Modeling some non-linear relationships with <code>mpg</code></a></span><ul class="toc-item"><li><span><a href="#local-regression" data-toc-modified-id="Local-Regression-3.1">Local Regression</a></span></li><li><span><a href="#Polynomial-Regression" data-toc-modified-id="Polynomial-Regression-3.2">Polynomial Regression</a></span></li><li><span><a href="#cubic-p-spline-regression" data-toc-modified-id="Cubic-P-Spline-Regression-3.3">Cubic P-Spline Regression</a></span></li><li><span><a href="#model-comparison" data-toc-modified-id="Model-Comparison-3.4">Model Comparison</a></span></li><li><span><a href="#optimal-models-and-their-test-errors" data-toc-modified-id="Optimal-models-and-their-test-errors-3.5">Optimal models and their test errors</a></span></li><li><span><a href="#analysis-of-optimal-models" data-toc-modified-id="Analysis-of-optimal-models-3.6">Analysis of optimal models</a></span></li><li><span><a href="#mpg-vs-accleration" data-toc-modified-id="mpg-vs-accleration-3.7"><code>mpg</code> vs <code>accleration</code></a></span></li><li><span><a href="#mpg-vs-weight" data-toc-modified-id="mpg-vs.-weight-3.8"><code>mpg</code> vs. <code>weight</code></a></span></li><li><span><a href="#mpg-vs-horsepower" data-toc-modified-id="mpg-vs.-horsepower-3.9"><code>mpg</code> vs. <code>horsepower</code></a></span></li><li><span><a href="#mpg-vs-displacement" data-toc-modified-id="mpg-vs.-displacement-3.10"><code>mpg</code> vs. <code>displacement</code></a></span></li></ul></li><li><span><a href="#gam-for-predicting-mpg" data-toc-modified-id="GAM-for-predicting-mpg-4">GAM for predicting <code>mpg</code></a></span><ul class="toc-item"><li><span><a href="#find-variables-with-linear-relationships-to-mpg" data-toc-modified-id="Find-variables-with-linear-relationships-to-mpg-4.1">Find variables with linear relationships to <code>mpg</code></a></span></li><li><span><a href="#train-gam" data-toc-modified-id="Train-GAM-4.2">Train GAM</a></span></li><li><span><a href="#compare-to-alternative-regression-models" data-toc-modified-id="Compare-to-alternative-regression-models-4.3">Compare to alternative regression models</a></span></li></ul></li></ul>
</div>

<h2 id="preparing-the-data">Preparing the data</h2>

<h3 id="import">Import</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># standard imports</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span><span class="p">;</span> <span class="n">sns</span><span class="o">.</span><span class="nb">set</span><span class="p">()</span>

<span class="n">auto</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'../../datasets/Auto.csv'</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">auto</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mpg</th>
      <th>cylinders</th>
      <th>displacement</th>
      <th>horsepower</th>
      <th>weight</th>
      <th>acceleration</th>
      <th>year</th>
      <th>origin</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>18.0</td>
      <td>8</td>
      <td>307.0</td>
      <td>130</td>
      <td>3504</td>
      <td>12.0</td>
      <td>70</td>
      <td>1</td>
      <td>chevrolet chevelle malibu</td>
    </tr>
    <tr>
      <th>2</th>
      <td>15.0</td>
      <td>8</td>
      <td>350.0</td>
      <td>165</td>
      <td>3693</td>
      <td>11.5</td>
      <td>70</td>
      <td>1</td>
      <td>buick skylark 320</td>
    </tr>
    <tr>
      <th>3</th>
      <td>18.0</td>
      <td>8</td>
      <td>318.0</td>
      <td>150</td>
      <td>3436</td>
      <td>11.0</td>
      <td>70</td>
      <td>1</td>
      <td>plymouth satellite</td>
    </tr>
    <tr>
      <th>4</th>
      <td>16.0</td>
      <td>8</td>
      <td>304.0</td>
      <td>150</td>
      <td>3433</td>
      <td>12.0</td>
      <td>70</td>
      <td>1</td>
      <td>amc rebel sst</td>
    </tr>
    <tr>
      <th>5</th>
      <td>17.0</td>
      <td>8</td>
      <td>302.0</td>
      <td>140</td>
      <td>3449</td>
      <td>10.5</td>
      <td>70</td>
      <td>1</td>
      <td>ford torino</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">auto</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 392 entries, 1 to 397
Data columns (total 9 columns):
mpg             392 non-null float64
cylinders       392 non-null int64
displacement    392 non-null float64
horsepower      392 non-null int64
weight          392 non-null int64
acceleration    392 non-null float64
year            392 non-null int64
origin          392 non-null int64
name            392 non-null object
dtypes: float64(3), int64(5), object(1)
memory usage: 30.6+ KB
</code></pre></div></div>

<h3 id="encode-categorical-variables">Encode categorical variables</h3>

<p>The only categorical (non-ordinal) variable is <code class="highlighter-rouge">origin</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># numerical df with one hot encoding for origin variable</span>
<span class="n">auto_num</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">auto</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'origin'</span><span class="p">])</span>
<span class="n">auto_num</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mpg</th>
      <th>cylinders</th>
      <th>displacement</th>
      <th>horsepower</th>
      <th>weight</th>
      <th>acceleration</th>
      <th>year</th>
      <th>name</th>
      <th>origin_1</th>
      <th>origin_2</th>
      <th>origin_3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>18.0</td>
      <td>8</td>
      <td>307.0</td>
      <td>130</td>
      <td>3504</td>
      <td>12.0</td>
      <td>70</td>
      <td>chevrolet chevelle malibu</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>15.0</td>
      <td>8</td>
      <td>350.0</td>
      <td>165</td>
      <td>3693</td>
      <td>11.5</td>
      <td>70</td>
      <td>buick skylark 320</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>18.0</td>
      <td>8</td>
      <td>318.0</td>
      <td>150</td>
      <td>3436</td>
      <td>11.0</td>
      <td>70</td>
      <td>plymouth satellite</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>16.0</td>
      <td>8</td>
      <td>304.0</td>
      <td>150</td>
      <td>3433</td>
      <td>12.0</td>
      <td>70</td>
      <td>amc rebel sst</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>17.0</td>
      <td>8</td>
      <td>302.0</td>
      <td>140</td>
      <td>3449</td>
      <td>10.5</td>
      <td>70</td>
      <td>ford torino</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="inspecting-the-data">Inspecting the Data</h2>

<p>Before training models we’ll do some inspection to see if non-linear relationships are suggested by the data.</p>

<p>A pairplot produces all possible scatterplots of the variables</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># pair plot to inspect distributions and scatterplots</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">auto</span><span class="p">,</span> <span class="n">diag_kind</span><span class="o">=</span><span class="s">'kde'</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span><span class="mf">0.5</span><span class="p">},</span>
             <span class="n">diag_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span><span class="mf">0.5</span><span class="p">})</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.PairGrid at 0x1a20dc77b8&gt;
</code></pre></div></div>

<p><img src="/islr/assets/images/ch07_exercise_08_10_1.png" alt="png" /></p>

<p>Observations:</p>

<ul>
  <li>The plots strongly suggest that variables <code class="highlighter-rouge">weight</code>, <code class="highlighter-rouge">horsepower</code> and <code class="highlighter-rouge">displacement</code> have non-linear relationships to <code class="highlighter-rouge">mpg</code></li>
  <li>The plots weakly suggest that <code class="highlighter-rouge">displacement</code> and <code class="highlighter-rouge">horsepower</code> may have a non-linear relationships to <code class="highlighter-rouge">acceleration</code></li>
  <li>There is strong suggestion of some linear relationships as well.</li>
  <li>It’s difficult to identify a non-linear relationship between two variables when one of them is discrete (e.g. <code class="highlighter-rouge">cylinders</code>, <code class="highlighter-rouge">year</code>)</li>
</ul>

<h2 id="modeling-some-non-linear-relationships-with-mpg">Modeling some non-linear relationships with <code class="highlighter-rouge">mpg</code></h2>

<p>Based on the pairplot we’ll investigate non-linear relationships between  <code class="highlighter-rouge">acceleration</code>, <code class="highlighter-rouge">weight</code>, <code class="highlighter-rouge">horsepower</code>, and <code class="highlighter-rouge">displacement</code> with <code class="highlighter-rouge">mpg</code>. We’ll try a few different types of models, using cross-validation to optimize, and then compare</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">'acceleration'</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">,</span> <span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'displacement'</span><span class="p">,</span> <span class="s">'mpg'</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">auto</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span>

<span class="c"># normalize</span>
<span class="n">df</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span> <span class="o">-</span> <span class="n">df</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="n">df</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="c"># series</span>
<span class="n">acc</span><span class="p">,</span> <span class="n">wt</span><span class="p">,</span> <span class="n">hp</span><span class="p">,</span> <span class="n">dp</span><span class="p">,</span> <span class="n">mpg</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">acceleration</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">horsepower</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">displacement</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">mpg</span><span class="o">.</span><span class="n">values</span>
</code></pre></div></div>

<h3 id="local-regression">Local Regression</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">lr_param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s">'n_neighbors'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="s">'weights'</span><span class="p">:</span> <span class="p">[</span><span class="s">'uniform'</span><span class="p">,</span> <span class="s">'distance'</span><span class="p">],</span> 
                     <span class="s">'p'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)}</span>
<span class="n">lr_searches</span> <span class="o">=</span> <span class="p">[</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">KNeighborsRegressor</span><span class="p">(),</span> <span class="n">lr_param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                         <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="n">var_pairs</span> <span class="o">=</span> <span class="p">{</span><span class="s">'acc_mpg'</span><span class="p">,</span> <span class="s">'wt_mpg'</span><span class="p">,</span> <span class="s">'hp_mpg'</span><span class="p">,</span> <span class="s">'dp_mpg'</span><span class="p">}</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span><span class="bp">None</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'local'</span><span class="p">,</span> <span class="s">'poly'</span><span class="p">,</span> <span class="s">'p-spline'</span><span class="p">]}</span>

<span class="n">models</span><span class="p">[</span><span class="s">'local'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">pair</span><span class="p">:</span><span class="bp">None</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">var_pairs</span><span class="p">}</span>
<span class="n">models</span><span class="p">[</span><span class="s">'local'</span><span class="p">][</span><span class="s">'acc_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_searches</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
<span class="n">models</span><span class="p">[</span><span class="s">'local'</span><span class="p">][</span><span class="s">'wt_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_searches</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">wt</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
<span class="n">models</span><span class="p">[</span><span class="s">'local'</span><span class="p">][</span><span class="s">'hp_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_searches</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
<span class="n">models</span><span class="p">[</span><span class="s">'local'</span><span class="p">][</span><span class="s">'dp_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_searches</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="polynomial-regression">Polynomial Regression</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="n">reg_tree_search</span><span class="o">.</span><span class="n">best_params_</span>

<span class="c"># 6-fold cv estimate of test rmse</span>
<span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">reg_tree_search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="c"># test set mse</span>
<span class="n">final_reg_tree</span> <span class="o">=</span> <span class="n">reg_tree_search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">reg_tree_test_mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">final_reg_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">reg_tree_test_mse</span><span class="p">)</span>
<span class="n">pr_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s">'poly'</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">()),</span> <span class="p">(</span><span class="s">'ridge'</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">())])</span>
<span class="n">pr_pipe_param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s">'poly__degree'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="s">'ridge__alpha'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)}</span>
<span class="n">pr_searches</span> <span class="o">=</span> <span class="p">[</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pr_pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">pr_pipe_param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                              <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="n">models</span><span class="p">[</span><span class="s">'poly'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">pair</span><span class="p">:</span><span class="bp">None</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">var_pairs</span><span class="p">}</span>
<span class="n">models</span><span class="p">[</span><span class="s">'poly'</span><span class="p">][</span><span class="s">'acc_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pr_searches</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
<span class="n">models</span><span class="p">[</span><span class="s">'poly'</span><span class="p">][</span><span class="s">'wt_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pr_searches</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">wt</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
<span class="n">models</span><span class="p">[</span><span class="s">'poly'</span><span class="p">][</span><span class="s">'hp_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pr_searches</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
<span class="n">models</span><span class="p">[</span><span class="s">'poly'</span><span class="p">][</span><span class="s">'dp_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pr_searches</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="cubic-p-spline-regression">Cubic P-Spline Regression</h3>

<p>Thankfully <code class="highlighter-rouge">pygam</code>’s <code class="highlighter-rouge">GAM</code> plays nice with <code class="highlighter-rouge">sklearn</code>’s <code class="highlighter-rouge">GridSearchCV</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pygam</span> <span class="kn">import</span> <span class="n">GAM</span><span class="p">,</span> <span class="n">s</span>

<span class="n">gam</span> <span class="o">=</span> <span class="n">GAM</span><span class="p">(</span><span class="n">s</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

<span class="n">ps_param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s">'n_splines'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="s">'spline_order'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> 
                 <span class="s">'lam'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()}</span>
<span class="n">ps_searches</span> <span class="o">=</span> <span class="p">[</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">GAM</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">ps_param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span>
               <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
</code></pre></div></div>

<p>Note that <code class="highlighter-rouge">pygam.GAM.gridsearch</code> uses generalized cross-validation (GCV).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="n">models</span><span class="p">[</span><span class="s">'p-spline'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">pair</span><span class="p">:</span><span class="bp">None</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">var_pairs</span><span class="p">}</span>
<span class="n">models</span><span class="p">[</span><span class="s">'p-spline'</span><span class="p">][</span><span class="s">'acc_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">ps_searches</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
<span class="n">models</span><span class="p">[</span><span class="s">'p-spline'</span><span class="p">][</span><span class="s">'wt_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">ps_searches</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">wt</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
<span class="n">models</span><span class="p">[</span><span class="s">'p-spline'</span><span class="p">][</span><span class="s">'hp_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">ps_searches</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
<span class="n">models</span><span class="p">[</span><span class="s">'p-spline'</span><span class="p">][</span><span class="s">'dp_mpg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">ps_searches</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mpg</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="model-comparison">Model Comparison</h3>

<h3 id="optimal-models-and-their-test-errors">Optimal models and their test errors</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cols</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="o">.</span><span class="n">from_product</span><span class="p">([[</span><span class="s">'acc_mpg'</span><span class="p">,</span> <span class="s">'wt_mpg'</span><span class="p">,</span> <span class="s">'hp_mpg'</span><span class="p">,</span> <span class="s">'dp_mpg'</span><span class="p">],</span> <span class="p">[</span><span class="s">'params'</span><span class="p">,</span> <span class="s">'cv_mse'</span><span class="p">]],</span> 
                                  <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s">'var_pair'</span><span class="p">,</span> <span class="s">'opt_results'</span><span class="p">])</span>
<span class="n">rows</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">([</span><span class="s">'local'</span><span class="p">,</span> <span class="s">'poly'</span><span class="p">,</span> <span class="s">'p-spline'</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">'model_type'</span><span class="p">)</span>
    
<span class="n">models_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">cols</span><span class="p">)</span>
<span class="n">models_df</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>var_pair</th>
      <th colspan="2" halign="left">acc_mpg</th>
      <th colspan="2" halign="left">wt_mpg</th>
      <th colspan="2" halign="left">hp_mpg</th>
      <th colspan="2" halign="left">dp_mpg</th>
    </tr>
    <tr>
      <th>opt_results</th>
      <th>params</th>
      <th>cv_mse</th>
      <th>params</th>
      <th>cv_mse</th>
      <th>params</th>
      <th>cv_mse</th>
      <th>params</th>
      <th>cv_mse</th>
    </tr>
    <tr>
      <th>model_type</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>local</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>poly</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>p-spline</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">var_pair</span> <span class="ow">in</span> <span class="n">models_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">levels</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">models_df</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
        <span class="n">models_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">name</span><span class="p">,</span> <span class="n">var_pair</span><span class="p">]</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="n">var_pair</span><span class="p">]</span><span class="o">.</span><span class="n">best_params_</span><span class="p">,</span> <span class="o">-</span><span class="n">models</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="n">var_pair</span><span class="p">]</span><span class="o">.</span><span class="n">best_score_</span>
        
<span class="n">models_df</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>var_pair</th>
      <th colspan="2" halign="left">acc_mpg</th>
      <th colspan="2" halign="left">wt_mpg</th>
      <th colspan="2" halign="left">hp_mpg</th>
      <th colspan="2" halign="left">dp_mpg</th>
    </tr>
    <tr>
      <th>opt_results</th>
      <th>params</th>
      <th>cv_mse</th>
      <th>params</th>
      <th>cv_mse</th>
      <th>params</th>
      <th>cv_mse</th>
      <th>params</th>
      <th>cv_mse</th>
    </tr>
    <tr>
      <th>model_type</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>local</th>
      <td>{'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}</td>
      <td>1.02543</td>
      <td>{'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}</td>
      <td>0.421562</td>
      <td>{'n_neighbors': 4, 'p': 1, 'weights': 'distance'}</td>
      <td>0.371018</td>
      <td>{'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}</td>
      <td>0.406882</td>
    </tr>
    <tr>
      <th>poly</th>
      <td>{'poly__degree': 4, 'ridge__alpha': 0.0001}</td>
      <td>0.969238</td>
      <td>{'poly__degree': 2, 'ridge__alpha': 0.0001}</td>
      <td>0.384849</td>
      <td>{'poly__degree': 2, 'ridge__alpha': 0.0001}</td>
      <td>0.399221</td>
      <td>{'poly__degree': 2, 'ridge__alpha': 0.0001}</td>
      <td>0.403257</td>
    </tr>
    <tr>
      <th>p-spline</th>
      <td>{'lam': 3.1804238375997853, 'n_splines': 10, '...</td>
      <td>0.970488</td>
      <td>{'lam': 3.1804238375997853, 'n_splines': 10, '...</td>
      <td>0.391603</td>
      <td>{'lam': 3.1804238375997853, 'n_splines': 10, '...</td>
      <td>0.376321</td>
      <td>{'lam': 3.1804238375997853, 'n_splines': 10, '...</td>
      <td>0.392898</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="analysis-of-optimal-models">Analysis of optimal models</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># helper for plotting results</span>

<span class="k">def</span> <span class="nf">plot_results</span><span class="p">(</span><span class="n">var_name</span><span class="p">,</span> <span class="n">var</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">model_type</span><span class="p">][</span><span class="n">var_name</span> <span class="o">+</span> <span class="s">'_mpg'</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">var</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> 
                     <span class="n">label</span><span class="o">=</span><span class="n">model_type</span> <span class="o">+</span> <span class="s">" regression prediction"</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">var</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">mpg</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'std '</span> <span class="o">+</span> <span class="n">var_name</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'std mpg'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="mpg-vs-accleration"><code class="highlighter-rouge">mpg</code> vs <code class="highlighter-rouge">accleration</code></h3>

<p>The models seem to have much harder time predicting <code class="highlighter-rouge">mpg</code> from <code class="highlighter-rouge">acceleration</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># mse estimates for acceleration models</span>
<span class="n">models_df</span><span class="p">[</span><span class="s">'acc_mpg'</span><span class="p">]</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>opt_results</th>
      <th>params</th>
      <th>cv_mse</th>
    </tr>
    <tr>
      <th>model_type</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>local</th>
      <td>{'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}</td>
      <td>1.02543</td>
    </tr>
    <tr>
      <th>poly</th>
      <td>{'poly__degree': 4, 'ridge__alpha': 0.0001}</td>
      <td>0.969238</td>
    </tr>
    <tr>
      <th>p-spline</th>
      <td>{'lam': 3.1804238375997853, 'n_splines': 10, '...</td>
      <td>0.970488</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_results</span><span class="p">(</span><span class="s">'acc'</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/islr/assets/images/ch07_exercise_08_35_0.png" alt="png" /></p>

<p>Observations:</p>

<ul>
  <li>The local regression model seems to be fitting noise</li>
  <li>The polynomial and p-spline models are smoother, and less likely to overfit, which is consistent with their lower mse estimates</li>
  <li>The relationship between <code class="highlighter-rouge">acceleration</code> and <code class="highlighter-rouge">mpg</code> appears weak</li>
</ul>

<p>Conclusion:</p>

<p>There is little evidence of a relationship (linear or otherwise) between <code class="highlighter-rouge">acceleration</code> and <code class="highlighter-rouge">mpg</code> so we’ll omit <code class="highlighter-rouge">acceleration</code> from the final model</p>

<h3 id="mpg-vs-weight"><code class="highlighter-rouge">mpg</code> vs. <code class="highlighter-rouge">weight</code></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># # mse estimates for acceleration models</span>
<span class="n">models_df</span><span class="p">[</span><span class="s">'wt_mpg'</span><span class="p">]</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>opt_results</th>
      <th>params</th>
      <th>cv_mse</th>
    </tr>
    <tr>
      <th>model_type</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>local</th>
      <td>{'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}</td>
      <td>0.421562</td>
    </tr>
    <tr>
      <th>poly</th>
      <td>{'poly__degree': 2, 'ridge__alpha': 0.0001}</td>
      <td>0.384849</td>
    </tr>
    <tr>
      <th>p-spline</th>
      <td>{'lam': 3.1804238375997853, 'n_splines': 10, '...</td>
      <td>0.391603</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_results</span><span class="p">(</span><span class="s">'wt'</span><span class="p">,</span> <span class="n">wt</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/islr/assets/images/ch07_exercise_08_39_0.png" alt="png" /></p>

<p>Observations:</p>

<ul>
  <li>The local regression model again seems to be fitting noise</li>
  <li>The polynomial and p-spline models are smoother, and less likely to overfit, which is consistent with their lower mse estimates</li>
  <li>The relationship between <code class="highlighter-rouge">weight</code> and <code class="highlighter-rouge">mpg</code> appears strong.</li>
  <li>The p-spline and polynomial regression mses are very similar</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models_df</span><span class="p">[(</span><span class="s">'wt_mpg'</span><span class="p">,</span> <span class="s">'params'</span><span class="p">)][</span><span class="s">'poly'</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'poly__degree': 2, 'ridge__alpha': 0.0001}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models_df</span><span class="p">[(</span><span class="s">'wt_mpg'</span><span class="p">,</span> <span class="s">'params'</span><span class="p">)][</span><span class="s">'p-spline'</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'lam': 3.1804238375997853, 'n_splines': 10, 'spline_order': 2}
</code></pre></div></div>

<p>Conclusion:</p>

<p>Optimal polynomial and p-spline models are both degree 2. Given its flexibility at the lower end of the range of <code class="highlighter-rouge">weight</code>, we’ll select the p-spline for the final model.</p>

<h3 id="mpg-vs-horsepower"><code class="highlighter-rouge">mpg</code> vs. <code class="highlighter-rouge">horsepower</code></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># # mse estimates for acceleration models</span>
<span class="n">models_df</span><span class="p">[</span><span class="s">'hp_mpg'</span><span class="p">]</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>opt_results</th>
      <th>params</th>
      <th>cv_mse</th>
    </tr>
    <tr>
      <th>model_type</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>local</th>
      <td>{'n_neighbors': 4, 'p': 1, 'weights': 'distance'}</td>
      <td>0.371018</td>
    </tr>
    <tr>
      <th>poly</th>
      <td>{'poly__degree': 2, 'ridge__alpha': 0.0001}</td>
      <td>0.399221</td>
    </tr>
    <tr>
      <th>p-spline</th>
      <td>{'lam': 3.1804238375997853, 'n_splines': 10, '...</td>
      <td>0.376321</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_results</span><span class="p">(</span><span class="s">'hp'</span><span class="p">,</span> <span class="n">hp</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/islr/assets/images/ch07_exercise_08_46_0.png" alt="png" /></p>

<p>Observations:</p>

<ul>
  <li>The local regression model again seems to be fitting noise</li>
  <li>The polynomial and p-spline models are smoother, and less likely to overfit, which is consistent with their lower mse estimates</li>
  <li>The relationship between <code class="highlighter-rouge">horsepower</code> and <code class="highlighter-rouge">mpg</code> appears strong.</li>
  <li>The p-spline and polynomial regression mses are very similar</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models_df</span><span class="p">[(</span><span class="s">'hp_mpg'</span><span class="p">,</span> <span class="s">'params'</span><span class="p">)][</span><span class="s">'poly'</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'poly__degree': 2, 'ridge__alpha': 0.0001}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models_df</span><span class="p">[(</span><span class="s">'hp_mpg'</span><span class="p">,</span> <span class="s">'params'</span><span class="p">)][</span><span class="s">'p-spline'</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'lam': 3.1804238375997853, 'n_splines': 10, 'spline_order': 2}
</code></pre></div></div>

<p>Conclusion:</p>

<p>Optimal polynomial and p-spline models are both degree 2. Given its flexibility at the lower end of the range of <code class="highlighter-rouge">weight</code>, we’ll select the p-spline for the final model.</p>

<h3 id="mpg-vs-displacement"><code class="highlighter-rouge">mpg</code> vs. <code class="highlighter-rouge">displacement</code></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># # mse estimates for acceleration models</span>
<span class="n">models_df</span><span class="p">[</span><span class="s">'dp_mpg'</span><span class="p">]</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>opt_results</th>
      <th>params</th>
      <th>cv_mse</th>
    </tr>
    <tr>
      <th>model_type</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>local</th>
      <td>{'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}</td>
      <td>0.406882</td>
    </tr>
    <tr>
      <th>poly</th>
      <td>{'poly__degree': 2, 'ridge__alpha': 0.0001}</td>
      <td>0.403257</td>
    </tr>
    <tr>
      <th>p-spline</th>
      <td>{'lam': 3.1804238375997853, 'n_splines': 10, '...</td>
      <td>0.392898</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_results</span><span class="p">(</span><span class="s">'dp'</span><span class="p">,</span> <span class="n">dp</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/islr/assets/images/ch07_exercise_08_53_0.png" alt="png" /></p>

<p>Observations:</p>

<ul>
  <li>The local regression model again seems to be fitting noise</li>
  <li>The polynomial and p-spline models are smoother, and less likely to overfit, which is consistent with their lower mse estimates</li>
  <li>The relationship between <code class="highlighter-rouge">displacement</code> and <code class="highlighter-rouge">mpg</code> appears strong.</li>
  <li>The p-spline and polynomial regression mses are very similar</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models_df</span><span class="p">[(</span><span class="s">'dp_mpg'</span><span class="p">,</span> <span class="s">'params'</span><span class="p">)][</span><span class="s">'poly'</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'poly__degree': 2, 'ridge__alpha': 0.0001}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models_df</span><span class="p">[(</span><span class="s">'dp_mpg'</span><span class="p">,</span> <span class="s">'params'</span><span class="p">)][</span><span class="s">'p-spline'</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'lam': 3.1804238375997853, 'n_splines': 10, 'spline_order': 2}
</code></pre></div></div>

<p>Conclusion:</p>

<p>Optimal polynomial and p-spline models are both degree 2. Given its flexibility at the lower end of the range of <code class="highlighter-rouge">weight</code>, we’ll select the p-spline for the final model.</p>

<h2 id="gam-for-predicting-mpg">GAM for predicting <code class="highlighter-rouge">mpg</code></h2>

<p>We identified some variables with non-linear relationships to <code class="highlighter-rouge">mpg</code> above, now we search for linear relationships. We’ll then fit a GAM which is a kind of hybrid model - linear on the linear variables, non-linear on the non-linear variables.</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><munder><mo>∑</mo><mtext>linear</mtext></munder><msub><mi>β</mi><mi>j</mi></msub><msub><mi>X</mi><mi>j</mi></msub><mo>+</mo><munder><mo>∑</mo><mtext>nonlinear</mtext></munder><msub><mi>β</mi><mi>k</mi></msub><msub><mi>f</mi><mi>k</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y = \beta_0 + \sum_{\text{linear}} \beta_j X_j + \sum_{\text{nonlinear}} \beta_k f_k(X_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.3521180000000004em;vertical-align:-1.3021129999999999em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0500050000000005em;"><span style="top:-1.847887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">linear</span></span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021129999999999em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.3521180000000004em;vertical-align:-1.3021129999999999em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0500050000000005em;"><span style="top:-1.847887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">nonlinear</span></span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021129999999999em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>

<p>where the nonlinear functions <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">f_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are those found above.</p>

<h3 id="find-variables-with-linear-relationships-to-mpg">Find variables with linear relationships to <code class="highlighter-rouge">mpg</code></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">auto</span><span class="o">.</span><span class="n">corr</span><span class="p">()[</span><span class="n">auto</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">]</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mpg</th>
      <th>cylinders</th>
      <th>displacement</th>
      <th>horsepower</th>
      <th>weight</th>
      <th>acceleration</th>
      <th>year</th>
      <th>origin</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mpg</th>
      <td>1.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.580541</td>
      <td>0.565209</td>
    </tr>
    <tr>
      <th>cylinders</th>
      <td>NaN</td>
      <td>1.000000</td>
      <td>0.950823</td>
      <td>0.842983</td>
      <td>0.897527</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>displacement</th>
      <td>NaN</td>
      <td>0.950823</td>
      <td>1.000000</td>
      <td>0.897257</td>
      <td>0.932994</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>horsepower</th>
      <td>NaN</td>
      <td>0.842983</td>
      <td>0.897257</td>
      <td>1.000000</td>
      <td>0.864538</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>weight</th>
      <td>NaN</td>
      <td>0.897527</td>
      <td>0.932994</td>
      <td>0.864538</td>
      <td>1.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>acceleration</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>year</th>
      <td>0.580541</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>origin</th>
      <td>0.565209</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="train-gam">Train GAM</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gam_df</span> <span class="o">=</span> <span class="n">auto_num</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">gam_df</span> <span class="o">=</span> <span class="n">gam_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'acceleration'</span><span class="p">,</span> <span class="s">'name'</span><span class="p">])</span>
<span class="n">num_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">'mpg'</span><span class="p">,</span> <span class="s">'cylinders'</span><span class="p">,</span> <span class="s">'displacement'</span><span class="p">,</span> <span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">,</span> <span class="s">'year'</span><span class="p">]</span>
<span class="n">gam_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:</span> <span class="p">,</span> <span class="n">num_cols</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">gam_df</span><span class="p">[</span><span class="n">num_cols</span><span class="p">]</span> <span class="o">-</span> <span class="n">gam_df</span><span class="p">[</span><span class="n">num_cols</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="n">gam_df</span><span class="p">[</span><span class="n">num_cols</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="n">gam_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mpg</th>
      <th>cylinders</th>
      <th>displacement</th>
      <th>horsepower</th>
      <th>weight</th>
      <th>year</th>
      <th>origin_1</th>
      <th>origin_2</th>
      <th>origin_3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>-0.697747</td>
      <td>1.482053</td>
      <td>1.075915</td>
      <td>0.663285</td>
      <td>0.619748</td>
      <td>-1.623241</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.082115</td>
      <td>1.482053</td>
      <td>1.486832</td>
      <td>1.572585</td>
      <td>0.842258</td>
      <td>-1.623241</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.697747</td>
      <td>1.482053</td>
      <td>1.181033</td>
      <td>1.182885</td>
      <td>0.539692</td>
      <td>-1.623241</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.953992</td>
      <td>1.482053</td>
      <td>1.047246</td>
      <td>1.182885</td>
      <td>0.536160</td>
      <td>-1.623241</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.825870</td>
      <td>1.482053</td>
      <td>1.028134</td>
      <td>0.923085</td>
      <td>0.554997</td>
      <td>-1.623241</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pygam</span> <span class="kn">import</span> <span class="n">f</span>

<span class="n">final_gam</span> <span class="o">=</span> <span class="n">GAM</span><span class="p">(</span><span class="n">s</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">s</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">s</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="n">s</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="o">+</span> <span class="n">s</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="n">f</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span> <span class="o">+</span> <span class="n">f</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span> <span class="o">+</span> <span class="n">f</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>

<span class="n">ps_param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s">'n_splines'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="s">'spline_order'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> 
                 <span class="s">'lam'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()}</span>
<span class="n">ps_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">GAM</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">ps_param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span>
<span class="n">ps_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">gam_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'mpg'</span><span class="p">]),</span> <span class="n">gam_df</span><span class="p">[</span><span class="s">'mpg'</span><span class="p">])</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/Users/home/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.
  DeprecationWarning)





GridSearchCV(cv=10, error_score='raise-deprecating',
       estimator=GAM(callbacks=['deviance', 'diffs'], distribution='normal',
   fit_intercept=True, link='identity', max_iter=100, terms='auto',
   tol=0.0001, verbose=False),
       fit_params=None, iid='warn', n_jobs=None,
       param_grid={'n_splines': array([15, 16, 17, 18, 19]), 'spline_order': array([2]), 'lam': array([1.22679, 1.71212, ..., 0.19191, 0.68306])},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring='neg_mean_squared_error', verbose=0)
</code></pre></div></div>

<h3 id="compare-to-alternative-regression-models">Compare to alternative regression models</h3>

<p>We’ll compare our GAM to to alternative null, ordinary least squares and polynomial ridge regression models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">gam_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'mpg'</span><span class="p">]),</span> <span class="n">gam_df</span><span class="p">[</span><span class="s">'mpg'</span><span class="p">]</span>

<span class="c"># dummy model that always predicts mean response</span>
<span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">dummy_cv_mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">dummy</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="c"># ordinary least squares</span>
<span class="n">ols</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">ols_cv_mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">ols</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="c"># optimized polynomial ridge</span>
<span class="n">pr_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s">'poly'</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">()),</span> <span class="p">(</span><span class="s">'ridge'</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">())])</span>
<span class="n">pr_pipe_param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s">'poly__degree'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="s">'ridge__alpha'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)}</span>
<span class="n">pr_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pr_pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">pr_pipe_param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                              <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">)</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">pr_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">ridge_cv_mse</span> <span class="o">=</span> <span class="o">-</span><span class="n">ridge</span><span class="o">.</span><span class="n">best_score_</span>

<span class="n">gam_cv_mse</span> <span class="o">=</span> <span class="o">-</span><span class="n">ps_search</span><span class="o">.</span><span class="n">best_score_</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/Users/home/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.
  DeprecationWarning)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">comparison_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'cv_mse'</span><span class="p">:</span> <span class="p">[</span><span class="n">dummy_cv_mse</span><span class="p">,</span> <span class="n">ols_cv_mse</span><span class="p">,</span> <span class="n">ridge_cv_mse</span><span class="p">,</span> <span class="n">gam_cv_mse</span><span class="p">]},</span> 
                             <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s">'dummy'</span><span class="p">,</span> <span class="s">'ols'</span><span class="p">,</span> <span class="s">'poly ridge'</span><span class="p">,</span> <span class="s">'gam'</span><span class="p">])</span>
<span class="n">comparison_df</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cv_mse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>dummy</th>
      <td>1.092509</td>
    </tr>
    <tr>
      <th>ols</th>
      <td>0.203995</td>
    </tr>
    <tr>
      <th>poly ridge</th>
      <td>0.127831</td>
    </tr>
    <tr>
      <th>gam</th>
      <td>0.201342</td>
    </tr>
  </tbody>
</table>
</div>

<p>The polynomial ridge model has outperformed</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ridge</span><span class="o">.</span><span class="n">best_params_</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'poly__degree': 3, 'ridge__alpha': 1.0}
</code></pre></div></div>


</div>

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', functione. {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
